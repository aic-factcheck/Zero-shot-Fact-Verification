{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import bert_score\n",
    "\n",
    "import unicodedata\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.batch import batch_apply\n",
    "from aic_nlp_utils.encoding import nfc\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "import stanza\n",
    "# stanza.download(\"en\")\n",
    "\n",
    "from zshot_fact_verify.models.arguments import ModelArguments, DataTrainingArguments\n",
    "from zshot_fact_verify.models.load import load_tokenizer_and_model, find_last_checkpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and Fix QA2D Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 41376 records to /mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\n",
      "writing 242840 records to /mnt/data/factcheck/qa2d/cs_en_pl_sk/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "def combine_qa2ds(split_files, out_file, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for sfile in split_files:\n",
    "        assert len(sfile.items()) == 1\n",
    "        for lang, path_ in sfile.items():\n",
    "            pass\n",
    "        split = read_jsonl(path_)\n",
    "        for s in split:\n",
    "            ta = s[\"turker_answer\"]\n",
    "            # temporal fix for lower case starting letters, should be fixed in all individual datasets\n",
    "            # see below :)\n",
    "            s[\"turker_answer\"] = ta[:1].upper() + ta[1:]\n",
    "            s[\"lang\"] = lang\n",
    "        data += split\n",
    "    rng.shuffle(data)\n",
    "    print(f\"writing {len(data)} records to {out_file}\")\n",
    "    write_jsonl(out_file, data, mkdir=True)\n",
    "\n",
    "combine_qa2ds([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qa2d/en/dev.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\"}], \n",
    "    \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\")\n",
    "\n",
    "combine_qa2ds([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qa2d/cs/train.jsonl\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qa2d/en/train.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qa2d/pl/train.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qa2d/sk/train.jsonl\"}], \n",
    "    \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 10344 records to /mnt/data/factcheck/qa2d/cs/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/en/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/pl/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/sk/dev.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/cs/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/en/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/pl/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/sk/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "def fix_qa2ds(split_files):\n",
    "    # answers sometimes started with lowe-case letters\n",
    "    for sfile in split_files:\n",
    "        lines = read_jsonl(sfile)\n",
    "        assert not Path(sfile + \".orig\").is_file(), f\"already exists: '{sfile}.orig'\"\n",
    "        Path(sfile).rename(sfile + \".orig\") # backup\n",
    "        for r in lines:\n",
    "            rb = r[\"rule-based\"]\n",
    "            ta = r[\"turker_answer\"]\n",
    "            r[\"rule-based\"] = rb[:1].upper() + rb[1:]\n",
    "            r[\"turker_answer\"] = ta[:1].upper() + ta[1:]\n",
    "        print(f\"writing {len(lines)} records to {sfile}\")\n",
    "        write_jsonl(sfile, lines, mkdir=True)\n",
    "\n",
    "fix_qa2ds([\n",
    "    \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/en/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\", \n",
    "    \"/mnt/data/factcheck/qa2d/cs/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/en/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/pl/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/sk/train.jsonl\", \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all\"\n",
    "MODEL_NAME_ALL2 = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_all/checkpoint-156000\"\n",
    "MODEL_NAME_CS1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_cs_CZ/checkpoint-76000\"\n",
    "MODEL_NAME_CS2 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_cs_CZ/checkpoint-26000\"\n",
    "MODEL_NAME_EN1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_en_US/checkpoint-30000\"\n",
    "MODEL_NAME_EN2 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_en_US/checkpoint-94000\"\n",
    "MODEL_NAME_PL1 = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_pl_PL/checkpoint-85000\"\n",
    "MODEL_NAME_SK1 = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_sk_SK/checkpoint-85000\"\n",
    "\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\"\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qa2d/en/dev.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "\n",
    "def predict_split_original(model, data):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"[SEP]\" + sample[\"question\"]) for sample in data]\n",
    "    Y = model.predict(X)\n",
    "    T = [sample[\"turker_answer\"] for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_original_model(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    model_args = Seq2SeqArgs()\n",
    "    model_args.max_length = 64\n",
    "    original_model = Seq2SeqModel(\n",
    "                encoder_decoder_type=\"bart\", \n",
    "                encoder_decoder_name=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/dependencies/QA2D_model\",\n",
    "                cuda_device=0,\n",
    "                args=model_args\n",
    "            )\n",
    "\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        print(f\"lang: {lang}, data file: {data_file}\")\n",
    "\n",
    "        data = read_jsonl(data_file)\n",
    "        print(f\"  loaded {len(data)} samples\")\n",
    "        \n",
    "        Y, T = predict_split_original(original_model, data)\n",
    "        \n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": \"original\", \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": \"original\", \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": \"original\", \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": \"original\", \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_original_model(cfgs, \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=True, device=\"cuda\"):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = model_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = model_inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "def predict_split(model, tokenizer, data, batch_size=16):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"</s>\" + sample[\"question\"]) for sample in data]\n",
    "    pfunc = lambda batch: predict(model, tokenizer, batch)\n",
    "    Y = batch_apply(pfunc, X, batch_size=batch_size, show_progress=True)\n",
    "    # some turker answers start with lower case letters; ROUGE ignores this but anyway,...\n",
    "    T = [nfc(sample[\"turker_answer\"][0:1].upper() + sample[\"turker_answer\"][1:]) for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_quality(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        model_name = cfg[\"model\"]\n",
    "        model_short = \"/\".join(Path(model_name).parts[8:])\n",
    "        print(f\"lang: {lang}, model: {model_short}, data file: {data_file}\")\n",
    "\n",
    "        data = read_jsonl(data_file)\n",
    "        print(f\"  loaded {len(data)} samples\")\n",
    "        \n",
    "        model_args = ModelArguments(model_name_or_path=model_name)\n",
    "        tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n",
    "        model.to(\"cuda\")\n",
    "        model.eval();\n",
    "\n",
    "        Y, T = predict_split(model, tokenizer, data, batch_size=16)\n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: pl_PL, model: experiments/qa2d/google/mt5-large_pl_PL/checkpoint-85000, data file: /mnt/data/factcheck/qa2d/pl/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01338052749633789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e47f843a1924c229f787444f0cb905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7671426770279015, 'rouge2': 0.6167445636811792, 'rougeL': 0.7122150031245609, 'rougeLsum': 0.7121087817666008, 'bert_score_P': 0.923403263092041, 'bert_score_R': 0.9220861792564392, 'bert_score_F1': 0.9225190281867981}\n",
      "---------------------------------------\n",
      "lang: sk_SK, model: experiments/qa2d/google/mt5-large_sk_SK/checkpoint-85000, data file: /mnt/data/factcheck/qa2d/sk/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00841212272644043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856091f366e41daa74483776e1b17a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7876781118384524, 'rouge2': 0.6400520532950926, 'rougeL': 0.7195672844868037, 'rougeLsum': 0.7193888996809157, 'bert_score_P': 0.9229689836502075, 'bert_score_R': 0.9209535717964172, 'bert_score_F1': 0.9217352867126465}\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    # {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS1, \"data_file\": DEV_FILE_CS},\n",
    "    # {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS2, \"data_file\": DEV_FILE_CS},\n",
    "    # {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN1, \"data_file\": DEV_FILE_EN},\n",
    "    # {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN2, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL1, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK1, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: experiments/qa2d/google/mt5-large_all/checkpoint-156000, data file: /mnt/data/factcheck/qa2d/cs/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009012937545776367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9569ddaaa5744f6cbf16abb0ee78a202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7829778956800801, 'rouge2': 0.6310825936825517, 'rougeL': 0.71030435160657, 'rougeLsum': 0.7104467150286194, 'bert_score_P': 0.9223543405532837, 'bert_score_R': 0.920818567276001, 'bert_score_F1': 0.9213548302650452}\n",
      "---------------------------------------\n",
      "lang: en_US, model: experiments/qa2d/google/mt5-large_all/checkpoint-156000, data file: /mnt/data/factcheck/qa2d/en/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00964808464050293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae67a6d077a4f5e80573109f153b43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.9348856529519217, 'rouge2': 0.8577113688879252, 'rougeL': 0.8872454655274765, 'rougeLsum': 0.887249012321926, 'bert_score_P': 0.9657933115959167, 'bert_score_R': 0.9641131162643433, 'bert_score_F1': 0.9648184776306152}\n",
      "---------------------------------------\n",
      "lang: pl_PL, model: experiments/qa2d/google/mt5-large_all/checkpoint-156000, data file: /mnt/data/factcheck/qa2d/pl/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009696245193481445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2b83b34d954658aea53d7bc8028c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7630884193918397, 'rouge2': 0.6101584128950617, 'rougeL': 0.7071874956951201, 'rougeLsum': 0.7073298532364101, 'bert_score_P': 0.9224919676780701, 'bert_score_R': 0.9208790063858032, 'bert_score_F1': 0.9214576482772827}\n",
      "---------------------------------------\n",
      "lang: sk_SK, model: experiments/qa2d/google/mt5-large_all/checkpoint-156000, data file: /mnt/data/factcheck/qa2d/sk/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008991718292236328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 647,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4364d7833e214be8b70f370fb9f6bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7855878556292287, 'rouge2': 0.636764481628465, 'rougeL': 0.7169630516951414, 'rougeLsum': 0.7170890600080113, 'bert_score_P': 0.9222889542579651, 'bert_score_R': 0.9202671051025391, 'bert_score_F1': 0.9210512042045593}\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_ALL},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bert_score_P</th>\n",
       "      <th>bert_score_R</th>\n",
       "      <th>bert_score_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>original</td>\n",
       "      <td>64.518723</td>\n",
       "      <td>44.506546</td>\n",
       "      <td>53.023387</td>\n",
       "      <td>53.024811</td>\n",
       "      <td>83.560187</td>\n",
       "      <td>84.120321</td>\n",
       "      <td>83.777118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>google/mt5-large_all/checkpoint-156000</td>\n",
       "      <td>78.297790</td>\n",
       "      <td>63.108259</td>\n",
       "      <td>71.030435</td>\n",
       "      <td>71.044672</td>\n",
       "      <td>92.235434</td>\n",
       "      <td>92.081857</td>\n",
       "      <td>92.135483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>facebook/mbart-large-cc25_cs_CZ/checkpoint-26000</td>\n",
       "      <td>77.367544</td>\n",
       "      <td>61.625559</td>\n",
       "      <td>69.675564</td>\n",
       "      <td>69.668337</td>\n",
       "      <td>91.769564</td>\n",
       "      <td>91.593200</td>\n",
       "      <td>91.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>google/mt5-large_cs_CZ/checkpoint-76000</td>\n",
       "      <td>78.527929</td>\n",
       "      <td>63.534912</td>\n",
       "      <td>71.298343</td>\n",
       "      <td>71.297282</td>\n",
       "      <td>92.314482</td>\n",
       "      <td>92.084652</td>\n",
       "      <td>92.175812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>77.822632</td>\n",
       "      <td>62.331959</td>\n",
       "      <td>70.382139</td>\n",
       "      <td>70.396227</td>\n",
       "      <td>92.128390</td>\n",
       "      <td>91.813821</td>\n",
       "      <td>91.946673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en_US</td>\n",
       "      <td>facebook/mbart-large-cc25_en_US/checkpoint-30000</td>\n",
       "      <td>93.051458</td>\n",
       "      <td>84.618493</td>\n",
       "      <td>87.766511</td>\n",
       "      <td>87.768816</td>\n",
       "      <td>96.241087</td>\n",
       "      <td>96.064985</td>\n",
       "      <td>96.138746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_en_US/checkpoint-94000</td>\n",
       "      <td>93.505732</td>\n",
       "      <td>85.850939</td>\n",
       "      <td>88.753483</td>\n",
       "      <td>88.740754</td>\n",
       "      <td>96.591437</td>\n",
       "      <td>96.395785</td>\n",
       "      <td>96.479940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>93.332366</td>\n",
       "      <td>85.458207</td>\n",
       "      <td>88.547557</td>\n",
       "      <td>88.547558</td>\n",
       "      <td>96.519303</td>\n",
       "      <td>96.288776</td>\n",
       "      <td>96.389705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_US</td>\n",
       "      <td>original</td>\n",
       "      <td>91.945534</td>\n",
       "      <td>82.951799</td>\n",
       "      <td>85.792845</td>\n",
       "      <td>85.790928</td>\n",
       "      <td>95.469755</td>\n",
       "      <td>95.382667</td>\n",
       "      <td>95.406002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_all/checkpoint-156000</td>\n",
       "      <td>93.488565</td>\n",
       "      <td>85.771137</td>\n",
       "      <td>88.724547</td>\n",
       "      <td>88.724901</td>\n",
       "      <td>96.579331</td>\n",
       "      <td>96.411312</td>\n",
       "      <td>96.481848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>original</td>\n",
       "      <td>62.283710</td>\n",
       "      <td>42.700628</td>\n",
       "      <td>53.304062</td>\n",
       "      <td>53.318436</td>\n",
       "      <td>84.236807</td>\n",
       "      <td>84.498507</td>\n",
       "      <td>84.304857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>google/mt5-large_pl_PL/checkpoint-85000</td>\n",
       "      <td>76.714268</td>\n",
       "      <td>61.674456</td>\n",
       "      <td>71.221500</td>\n",
       "      <td>71.210878</td>\n",
       "      <td>92.340326</td>\n",
       "      <td>92.208618</td>\n",
       "      <td>92.251903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>75.778406</td>\n",
       "      <td>60.404806</td>\n",
       "      <td>70.094379</td>\n",
       "      <td>70.101898</td>\n",
       "      <td>92.133784</td>\n",
       "      <td>91.854870</td>\n",
       "      <td>91.970444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>google/mt5-large_all/checkpoint-156000</td>\n",
       "      <td>76.308842</td>\n",
       "      <td>61.015841</td>\n",
       "      <td>70.718750</td>\n",
       "      <td>70.732985</td>\n",
       "      <td>92.249197</td>\n",
       "      <td>92.087901</td>\n",
       "      <td>92.145765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>77.956304</td>\n",
       "      <td>62.831569</td>\n",
       "      <td>70.871234</td>\n",
       "      <td>70.879449</td>\n",
       "      <td>92.093867</td>\n",
       "      <td>91.782957</td>\n",
       "      <td>91.913998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_all/checkpoint-156000</td>\n",
       "      <td>78.558786</td>\n",
       "      <td>63.676448</td>\n",
       "      <td>71.696305</td>\n",
       "      <td>71.708906</td>\n",
       "      <td>92.228895</td>\n",
       "      <td>92.026711</td>\n",
       "      <td>92.105120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>original</td>\n",
       "      <td>63.068046</td>\n",
       "      <td>42.986322</td>\n",
       "      <td>51.868467</td>\n",
       "      <td>51.863330</td>\n",
       "      <td>82.785422</td>\n",
       "      <td>83.815187</td>\n",
       "      <td>83.227086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_sk_SK/checkpoint-85000</td>\n",
       "      <td>78.767811</td>\n",
       "      <td>64.005205</td>\n",
       "      <td>71.956728</td>\n",
       "      <td>71.938890</td>\n",
       "      <td>92.296898</td>\n",
       "      <td>92.095357</td>\n",
       "      <td>92.173529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang                                             model     rouge1  \\\n",
       "0   cs_CZ                                          original  64.518723   \n",
       "12  cs_CZ            google/mt5-large_all/checkpoint-156000  78.297790   \n",
       "5   cs_CZ  facebook/mbart-large-cc25_cs_CZ/checkpoint-26000  77.367544   \n",
       "4   cs_CZ           google/mt5-large_cs_CZ/checkpoint-76000  78.527929   \n",
       "8   cs_CZ                         qa2d/google/umt5-base_all  77.822632   \n",
       "6   en_US  facebook/mbart-large-cc25_en_US/checkpoint-30000  93.051458   \n",
       "7   en_US           google/mt5-large_en_US/checkpoint-94000  93.505732   \n",
       "9   en_US                         qa2d/google/umt5-base_all  93.332366   \n",
       "1   en_US                                          original  91.945534   \n",
       "13  en_US            google/mt5-large_all/checkpoint-156000  93.488565   \n",
       "2   pl_PL                                          original  62.283710   \n",
       "16  pl_PL           google/mt5-large_pl_PL/checkpoint-85000  76.714268   \n",
       "10  pl_PL                         qa2d/google/umt5-base_all  75.778406   \n",
       "14  pl_PL            google/mt5-large_all/checkpoint-156000  76.308842   \n",
       "11  sk_SK                         qa2d/google/umt5-base_all  77.956304   \n",
       "15  sk_SK            google/mt5-large_all/checkpoint-156000  78.558786   \n",
       "3   sk_SK                                          original  63.068046   \n",
       "17  sk_SK           google/mt5-large_sk_SK/checkpoint-85000  78.767811   \n",
       "\n",
       "       rouge2     rougeL  rougeLsum  bert_score_P  bert_score_R  bert_score_F1  \n",
       "0   44.506546  53.023387  53.024811     83.560187     84.120321      83.777118  \n",
       "12  63.108259  71.030435  71.044672     92.235434     92.081857      92.135483  \n",
       "5   61.625559  69.675564  69.668337     91.769564     91.593200      91.656566  \n",
       "4   63.534912  71.298343  71.297282     92.314482     92.084652      92.175812  \n",
       "8   62.331959  70.382139  70.396227     92.128390     91.813821      91.946673  \n",
       "6   84.618493  87.766511  87.768816     96.241087     96.064985      96.138746  \n",
       "7   85.850939  88.753483  88.740754     96.591437     96.395785      96.479940  \n",
       "9   85.458207  88.547557  88.547558     96.519303     96.288776      96.389705  \n",
       "1   82.951799  85.792845  85.790928     95.469755     95.382667      95.406002  \n",
       "13  85.771137  88.724547  88.724901     96.579331     96.411312      96.481848  \n",
       "2   42.700628  53.304062  53.318436     84.236807     84.498507      84.304857  \n",
       "16  61.674456  71.221500  71.210878     92.340326     92.208618      92.251903  \n",
       "10  60.404806  70.094379  70.101898     92.133784     91.854870      91.970444  \n",
       "14  61.015841  70.718750  70.732985     92.249197     92.087901      92.145765  \n",
       "11  62.831569  70.871234  70.879449     92.093867     91.782957      91.913998  \n",
       "15  63.676448  71.696305  71.708906     92.228895     92.026711      92.105120  \n",
       "3   42.986322  51.868467  51.863330     82.785422     83.815187      83.227086  \n",
       "17  64.005205  71.956728  71.938890     92.296898     92.095357      92.173529  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_qa2d(result_jsonls):\n",
    "    data = []\n",
    "    for rjsonl in result_jsonls:\n",
    "        data += read_jsonl(rjsonl)\n",
    "    # for d in data:\n",
    "    #     t = d[\"eval\"][\"bert_score_R1\"]\n",
    "    #     d[\"eval\"][\"bert_score_R\"] = t\n",
    "    #     del d[\"eval\"][\"bert_score_R1\"]\n",
    "    # write_jsonl(result_jsonls[0], data)\n",
    "    # return\n",
    "    df = pd.DataFrame(data)\n",
    "    models = ['/'.join(m.split(\"/\")[-3:]) for m in df.model]\n",
    "    df[\"model\"] = models\n",
    "    df[\"rouge1\"] = [100*e[\"rouge1\"] for e in df[\"eval\"]]\n",
    "    df[\"rouge2\"] = [100*e[\"rouge2\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeL\"] = [100*e[\"rougeL\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeLsum\"] = [100*e[\"rougeLsum\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_P\"] = [100*e[\"bert_score_P\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_R\"] = [100*e[\"bert_score_R\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_F1\"] = [100*e[\"bert_score_F1\"] for e in df[\"eval\"]]\n",
    "    df = df[[\"lang\", \"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\", \"bert_score_P\", \"bert_score_R\", \"bert_score_F1\"]]\n",
    "    df.sort_values(\"lang\", inplace=True)\n",
    "    return df\n",
    "\n",
    "df = compare_results_qa2d([\n",
    "    \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\"\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " lang &                                            model &  rouge1 &  rouge2 &  rougeL &  bert\\_score\\_F1 \\\\\n",
      "\\midrule\n",
      "cs\\_CZ &                                         original &    64.5 &    44.5 &    53.0 &           83.8 \\\\\n",
      "cs\\_CZ &           google/mt5-large\\_all/checkpoint-156000 &    78.3 &    63.1 &    71.0 &           92.1 \\\\\n",
      "cs\\_CZ & facebook/mbart-large-cc25\\_cs\\_CZ/checkpoint-26000 &    77.4 &    61.6 &    69.7 &           91.7 \\\\\n",
      "cs\\_CZ &          google/mt5-large\\_cs\\_CZ/checkpoint-76000 &    78.5 &    63.5 &    71.3 &           92.2 \\\\\n",
      "en\\_US & facebook/mbart-large-cc25\\_en\\_US/checkpoint-30000 &    93.1 &    84.6 &    87.8 &           96.1 \\\\\n",
      "en\\_US &          google/mt5-large\\_en\\_US/checkpoint-94000 &    93.5 &    85.9 &    88.8 &           96.5 \\\\\n",
      "en\\_US &                                         original &    91.9 &    83.0 &    85.8 &           95.4 \\\\\n",
      "en\\_US &           google/mt5-large\\_all/checkpoint-156000 &    93.5 &    85.8 &    88.7 &           96.5 \\\\\n",
      "pl\\_PL &                                         original &    62.3 &    42.7 &    53.3 &           84.3 \\\\\n",
      "pl\\_PL &          google/mt5-large\\_pl\\_PL/checkpoint-85000 &    76.7 &    61.7 &    71.2 &           92.3 \\\\\n",
      "pl\\_PL &           google/mt5-large\\_all/checkpoint-156000 &    76.3 &    61.0 &    70.7 &           92.1 \\\\\n",
      "sk\\_SK &           google/mt5-large\\_all/checkpoint-156000 &    78.6 &    63.7 &    71.7 &           92.1 \\\\\n",
      "sk\\_SK &                                         original &    63.1 &    43.0 &    51.9 &           83.2 \\\\\n",
      "sk\\_SK &          google/mt5-large\\_sk\\_SK/checkpoint-85000 &    78.8 &    64.0 &    72.0 &           92.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1465890/2262563657.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))\n"
     ]
    }
   ],
   "source": [
    "print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_jsonl(\"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qacg/google/mt5_results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'lang': 'all',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.8121849974992059,\n",
    "   'rouge2': 0.6774419510196882,\n",
    "   'rougeL': 0.7497730778117646,\n",
    "   'rougeLsum': 0.7497340248321841}},\n",
    " {'lang': 'cs_CZ',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/cs/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7783607331568722,\n",
    "   'rouge2': 0.6231575608427122,\n",
    "   'rougeL': 0.7039034412670073,\n",
    "   'rougeLsum': 0.703985133472832}},\n",
    " {'lang': 'en_US',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/en/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.9333374676443688,\n",
    "   'rouge2': 0.8544504708653158,\n",
    "   'rougeL': 0.88537866791236,\n",
    "   'rougeLsum': 0.8855242981238776}},\n",
    " {'lang': 'pl_PL',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/pl/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7579418551444153,\n",
    "   'rouge2': 0.6037844541036594,\n",
    "   'rougeL': 0.70104065486047,\n",
    "   'rougeLsum': 0.7011065700120231}},\n",
    " {'lang': 'sk_SK',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/sk/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7796807605964733,\n",
    "   'rouge2': 0.6282711920363941,\n",
    "   'rougeL': 0.7087832206401827,\n",
    "   'rougeLsum': 0.7089273080145163}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-26000\")\n",
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=\"cs_CZ\", fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proč organismy dědí vlastnosti svých rodičů?\n",
      "buňky potomků obsahují kopie genů z buněk jejich rodičů\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['organismy dědí vlastnosti svých rodičů, protože buňky potomků obsahují kopie genů z buněk jejich rodičů.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    model_inputs = {k: model_inputs[k].to(\"cuda\") for k in model_inputs.keys()}\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[6]\n",
    "question = sample[\"question\"]\n",
    "answer = sample[\"answer\"]\n",
    "# question = \"V kolika letech zemřel Petr?\"\n",
    "# answer = \"25\"\n",
    "print(textwrap.fill(question))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflarge",
   "language": "python",
   "name": "hflarge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import bert_score\n",
    "\n",
    "import unicodedata\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.batch import batch_apply\n",
    "from aic_nlp_utils.encoding import nfc\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "import stanza\n",
    "# stanza.download(\"en\")\n",
    "\n",
    "from zshot_fact_verify.models.arguments import ModelArguments, DataTrainingArguments\n",
    "from zshot_fact_verify.models.load import load_tokenizer_and_model, find_last_checkpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and Fix QA2D Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 41376 records to /mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\n",
      "writing 242840 records to /mnt/data/factcheck/qa2d/cs_en_pl_sk/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "def combine_qa2ds(split_files, out_file, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for sfile in split_files:\n",
    "        assert len(sfile.items()) == 1\n",
    "        for lang, path_ in sfile.items():\n",
    "            pass\n",
    "        split = read_jsonl(path_)\n",
    "        for s in split:\n",
    "            ta = s[\"turker_answer\"]\n",
    "            # temporal fix for lower case starting letters, should be fixed in all individual datasets\n",
    "            # see below :)\n",
    "            s[\"turker_answer\"] = ta[:1].upper() + ta[1:]\n",
    "            s[\"lang\"] = lang\n",
    "        data += split\n",
    "    rng.shuffle(data)\n",
    "    print(f\"writing {len(data)} records to {out_file}\")\n",
    "    write_jsonl(out_file, data, mkdir=True)\n",
    "\n",
    "combine_qa2ds([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qa2d/en/dev.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\"}], \n",
    "    \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\")\n",
    "\n",
    "combine_qa2ds([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qa2d/cs/train.jsonl\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qa2d/en/train.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qa2d/pl/train.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qa2d/sk/train.jsonl\"}], \n",
    "    \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 10344 records to /mnt/data/factcheck/qa2d/cs/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/en/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/pl/dev.jsonl\n",
      "writing 10344 records to /mnt/data/factcheck/qa2d/sk/dev.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/cs/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/en/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/pl/train.jsonl\n",
      "writing 60710 records to /mnt/data/factcheck/qa2d/sk/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "def fix_qa2ds(split_files):\n",
    "    # answers sometimes started with lowe-case letters\n",
    "    for sfile in split_files:\n",
    "        lines = read_jsonl(sfile)\n",
    "        assert not Path(sfile + \".orig\").is_file(), f\"already exists: '{sfile}.orig'\"\n",
    "        Path(sfile).rename(sfile + \".orig\") # backup\n",
    "        for r in lines:\n",
    "            rb = r[\"rule-based\"]\n",
    "            ta = r[\"turker_answer\"]\n",
    "            r[\"rule-based\"] = rb[:1].upper() + rb[1:]\n",
    "            r[\"turker_answer\"] = ta[:1].upper() + ta[1:]\n",
    "        print(f\"writing {len(lines)} records to {sfile}\")\n",
    "        write_jsonl(sfile, lines, mkdir=True)\n",
    "\n",
    "fix_qa2ds([\n",
    "    \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/en/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\", \n",
    "    \"/mnt/data/factcheck/qa2d/cs/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/en/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/pl/train.jsonl\",\n",
    "    \"/mnt/data/factcheck/qa2d/sk/train.jsonl\", \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all\"\n",
    "MODEL_NAME_ALL2 = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_all/BKP/checkpoint-121000\"\n",
    "MODEL_NAME_CS1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_cs_CZ/checkpoint-76000\"\n",
    "MODEL_NAME_CS2 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_cs_CZ/checkpoint-26000\"\n",
    "MODEL_NAME_EN1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_en_US/checkpoint-30000\"\n",
    "MODEL_NAME_EN2 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/mt5-large_en_US/checkpoint-94000\"\n",
    "# MODEL_NAME_PL1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_pl_PL/checkpoint-43000\"\n",
    "# MODEL_NAME_SK1 = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_sk_SK/checkpoint-37000\"\n",
    "\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\"\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qa2d/cs/dev.jsonl\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qa2d/en/dev.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qa2d/pl/dev.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qa2d/sk/dev.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "\n",
    "def predict_split_original(model, data):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"[SEP]\" + sample[\"question\"]) for sample in data]\n",
    "    Y = model.predict(X)\n",
    "    T = [sample[\"turker_answer\"] for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_original_model(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    model_args = Seq2SeqArgs()\n",
    "    model_args.max_length = 64\n",
    "    original_model = Seq2SeqModel(\n",
    "                encoder_decoder_type=\"bart\", \n",
    "                encoder_decoder_name=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/dependencies/QA2D_model\",\n",
    "                cuda_device=0,\n",
    "                args=model_args\n",
    "            )\n",
    "\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        print(f\"lang: {lang}, data file: {data_file}\")\n",
    "\n",
    "        data = read_jsonl(data_file)\n",
    "        print(f\"  loaded {len(data)} samples\")\n",
    "        \n",
    "        Y, T = predict_split_original(original_model, data)\n",
    "        \n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": \"original\", \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": \"original\", \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": \"original\", \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": \"original\", \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_original_model(cfgs, \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=True, device=\"cuda\"):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = model_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = model_inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "def predict_split(model, tokenizer, data, batch_size=32):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"</s>\" + sample[\"question\"]) for sample in data]\n",
    "    pfunc = lambda batch: predict(model, tokenizer, batch)\n",
    "    Y = batch_apply(pfunc, X, batch_size=batch_size, show_progress=True)\n",
    "    # some turker answers start with lower case letters; ROUGE ignores this but anyway,...\n",
    "    T = [nfc(sample[\"turker_answer\"][0:1].upper() + sample[\"turker_answer\"][1:]) for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_quality(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        model_name = cfg[\"model\"]\n",
    "        model_short = \"/\".join(Path(model_name).parts[8:])\n",
    "        print(f\"lang: {lang}, model: {model_short}, data file: {data_file}\")\n",
    "\n",
    "        data = read_jsonl(data_file)\n",
    "        print(f\"  loaded {len(data)} samples\")\n",
    "        \n",
    "        model_args = ModelArguments(model_name_or_path=model_name)\n",
    "        tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n",
    "        model.to(\"cuda\")\n",
    "        model.eval();\n",
    "\n",
    "        Y, T = predict_split(model, tokenizer, data, batch_size=32)\n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        print(\"---------------------------------------\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS2, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS1, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN1, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN2, \"data_file\": DEV_FILE_EN},\n",
    "    # {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL1, \"data_file\": DEV_FILE_PL},\n",
    "    # {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK1, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: all, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl\n",
      "  loaded 41376 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008821725845336914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1293,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68338bda73f42fa8a4ebb940effe589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.8122218120177676, 'rouge2': 0.6774367151770639, 'rougeL': 0.7498164591304859, 'rougeLsum': 0.7497761148519413, 'bert_score_P': 0.9321883916854858, 'bert_score_R': 0.9293510317802429, 'bert_score_F1': 0.930552065372467}\n",
      "---------------------------------------\n",
      "lang: cs_CZ, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qa2d/cs/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008929967880249023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 324,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cedff999c0d4a4ab2ff8efa3ea4f534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7781002659870636, 'rouge2': 0.6232363149620266, 'rougeL': 0.7038499291502314, 'rougeLsum': 0.7038628248956882, 'bert_score_P': 0.9212839007377625, 'bert_score_R': 0.9181382060050964, 'bert_score_F1': 0.9194667339324951}\n",
      "---------------------------------------\n",
      "lang: en_US, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qa2d/en/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008295774459838867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 324,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a495227bc1fc495bbd0265b292cf5364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.9332151559207333, 'rouge2': 0.8545758468590733, 'rougeL': 0.885467944163314, 'rougeLsum': 0.8854070582375144, 'bert_score_P': 0.9651930332183838, 'bert_score_R': 0.9628877639770508, 'bert_score_F1': 0.9638970494270325}\n",
      "---------------------------------------\n",
      "lang: pl_PL, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qa2d/pl/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008780956268310547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 324,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e2000ce88640fb9badf10af8fe99d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7577914458960934, 'rouge2': 0.6038776767322465, 'rougeL': 0.7010437934418678, 'rougeLsum': 0.7009633554413504, 'bert_score_P': 0.9213378429412842, 'bert_score_R': 0.9185487031936646, 'bert_score_F1': 0.9197044372558594}\n",
      "---------------------------------------\n",
      "lang: sk_SK, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qa2d/sk/dev.jsonl\n",
      "  loaded 10344 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008452415466308594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 324,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e2019df31d4f69ad46e2533862b0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.7794955482700204, 'rouge2': 0.6281938885964595, 'rougeL': 0.7089312577856803, 'rougeLsum': 0.7086990889936273, 'bert_score_P': 0.9209386706352234, 'bert_score_R': 0.9178295731544495, 'bert_score_F1': 0.9191399812698364}\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\"lang\": \"all\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_ALL},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL2, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \n",
    "                         \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bert_score_P</th>\n",
       "      <th>bert_score_R</th>\n",
       "      <th>bert_score_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-121000</td>\n",
       "      <td>0.817812</td>\n",
       "      <td>0.685361</td>\n",
       "      <td>0.756357</td>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.933643</td>\n",
       "      <td>0.931691</td>\n",
       "      <td>0.932459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>all</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.812222</td>\n",
       "      <td>0.677437</td>\n",
       "      <td>0.749816</td>\n",
       "      <td>0.749776</td>\n",
       "      <td>0.932188</td>\n",
       "      <td>0.929351</td>\n",
       "      <td>0.930552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>original</td>\n",
       "      <td>0.645022</td>\n",
       "      <td>0.445025</td>\n",
       "      <td>0.530238</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.835602</td>\n",
       "      <td>0.841203</td>\n",
       "      <td>0.837771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>facebook/mbart-large-cc25_cs_CZ/checkpoint-26000</td>\n",
       "      <td>0.773603</td>\n",
       "      <td>0.616280</td>\n",
       "      <td>0.696729</td>\n",
       "      <td>0.696732</td>\n",
       "      <td>0.917696</td>\n",
       "      <td>0.915932</td>\n",
       "      <td>0.916566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>google/mt5-large_cs_CZ/checkpoint-76000</td>\n",
       "      <td>0.785204</td>\n",
       "      <td>0.635334</td>\n",
       "      <td>0.712915</td>\n",
       "      <td>0.712964</td>\n",
       "      <td>0.923145</td>\n",
       "      <td>0.920847</td>\n",
       "      <td>0.921758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-121000</td>\n",
       "      <td>0.784969</td>\n",
       "      <td>0.633072</td>\n",
       "      <td>0.711863</td>\n",
       "      <td>0.712106</td>\n",
       "      <td>0.923036</td>\n",
       "      <td>0.920931</td>\n",
       "      <td>0.921752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.778100</td>\n",
       "      <td>0.623236</td>\n",
       "      <td>0.703850</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.921284</td>\n",
       "      <td>0.918138</td>\n",
       "      <td>0.919467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.933215</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.885468</td>\n",
       "      <td>0.885407</td>\n",
       "      <td>0.965193</td>\n",
       "      <td>0.962888</td>\n",
       "      <td>0.963897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en_US</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-121000</td>\n",
       "      <td>0.935298</td>\n",
       "      <td>0.858313</td>\n",
       "      <td>0.887878</td>\n",
       "      <td>0.887918</td>\n",
       "      <td>0.965979</td>\n",
       "      <td>0.963956</td>\n",
       "      <td>0.964828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_en_US/checkpoint-94000</td>\n",
       "      <td>0.935031</td>\n",
       "      <td>0.858347</td>\n",
       "      <td>0.887431</td>\n",
       "      <td>0.887499</td>\n",
       "      <td>0.965914</td>\n",
       "      <td>0.963958</td>\n",
       "      <td>0.964799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en_US</td>\n",
       "      <td>facebook/mbart-large-cc25_en_US/checkpoint-30000</td>\n",
       "      <td>0.930450</td>\n",
       "      <td>0.846039</td>\n",
       "      <td>0.877568</td>\n",
       "      <td>0.877724</td>\n",
       "      <td>0.962411</td>\n",
       "      <td>0.960650</td>\n",
       "      <td>0.961387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en_US</td>\n",
       "      <td>original</td>\n",
       "      <td>0.919495</td>\n",
       "      <td>0.829395</td>\n",
       "      <td>0.857826</td>\n",
       "      <td>0.857937</td>\n",
       "      <td>0.954698</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.954060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>original</td>\n",
       "      <td>0.622598</td>\n",
       "      <td>0.426912</td>\n",
       "      <td>0.533043</td>\n",
       "      <td>0.533114</td>\n",
       "      <td>0.842368</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.843049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-121000</td>\n",
       "      <td>0.764814</td>\n",
       "      <td>0.611931</td>\n",
       "      <td>0.708388</td>\n",
       "      <td>0.708503</td>\n",
       "      <td>0.922584</td>\n",
       "      <td>0.921345</td>\n",
       "      <td>0.921740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.757791</td>\n",
       "      <td>0.603878</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.700963</td>\n",
       "      <td>0.921338</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.919704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>original</td>\n",
       "      <td>0.630492</td>\n",
       "      <td>0.429650</td>\n",
       "      <td>0.518672</td>\n",
       "      <td>0.518505</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>0.838152</td>\n",
       "      <td>0.832271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-121000</td>\n",
       "      <td>0.786326</td>\n",
       "      <td>0.637672</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>0.717323</td>\n",
       "      <td>0.922971</td>\n",
       "      <td>0.920531</td>\n",
       "      <td>0.921517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.779496</td>\n",
       "      <td>0.628194</td>\n",
       "      <td>0.708931</td>\n",
       "      <td>0.708699</td>\n",
       "      <td>0.920939</td>\n",
       "      <td>0.917830</td>\n",
       "      <td>0.919140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang                                             model    rouge1  \\\n",
       "0     all               mt5-large_all/BKP/checkpoint-121000  0.817812   \n",
       "13    all                         qa2d/google/umt5-base_all  0.812222   \n",
       "1   cs_CZ                                          original  0.645022   \n",
       "2   cs_CZ  facebook/mbart-large-cc25_cs_CZ/checkpoint-26000  0.773603   \n",
       "3   cs_CZ           google/mt5-large_cs_CZ/checkpoint-76000  0.785204   \n",
       "4   cs_CZ               mt5-large_all/BKP/checkpoint-121000  0.784969   \n",
       "14  cs_CZ                         qa2d/google/umt5-base_all  0.778100   \n",
       "15  en_US                         qa2d/google/umt5-base_all  0.933215   \n",
       "8   en_US               mt5-large_all/BKP/checkpoint-121000  0.935298   \n",
       "7   en_US           google/mt5-large_en_US/checkpoint-94000  0.935031   \n",
       "6   en_US  facebook/mbart-large-cc25_en_US/checkpoint-30000  0.930450   \n",
       "5   en_US                                          original  0.919495   \n",
       "9   pl_PL                                          original  0.622598   \n",
       "10  pl_PL               mt5-large_all/BKP/checkpoint-121000  0.764814   \n",
       "16  pl_PL                         qa2d/google/umt5-base_all  0.757791   \n",
       "11  sk_SK                                          original  0.630492   \n",
       "12  sk_SK               mt5-large_all/BKP/checkpoint-121000  0.786326   \n",
       "17  sk_SK                         qa2d/google/umt5-base_all  0.779496   \n",
       "\n",
       "      rouge2    rougeL  rougeLsum  bert_score_P  bert_score_R  bert_score_F1  \n",
       "0   0.685361  0.756357   0.756424      0.933643      0.931691       0.932459  \n",
       "13  0.677437  0.749816   0.749776      0.932188      0.929351       0.930552  \n",
       "1   0.445025  0.530238   0.530233      0.835602      0.841203       0.837771  \n",
       "2   0.616280  0.696729   0.696732      0.917696      0.915932       0.916566  \n",
       "3   0.635334  0.712915   0.712964      0.923145      0.920847       0.921758  \n",
       "4   0.633072  0.711863   0.712106      0.923036      0.920931       0.921752  \n",
       "14  0.623236  0.703850   0.703863      0.921284      0.918138       0.919467  \n",
       "15  0.854576  0.885468   0.885407      0.965193      0.962888       0.963897  \n",
       "8   0.858313  0.887878   0.887918      0.965979      0.963956       0.964828  \n",
       "7   0.858347  0.887431   0.887499      0.965914      0.963958       0.964799  \n",
       "6   0.846039  0.877568   0.877724      0.962411      0.960650       0.961387  \n",
       "5   0.829395  0.857826   0.857937      0.954698      0.953827       0.954060  \n",
       "9   0.426912  0.533043   0.533114      0.842368      0.844985       0.843049  \n",
       "10  0.611931  0.708388   0.708503      0.922584      0.921345       0.921740  \n",
       "16  0.603878  0.701044   0.700963      0.921338      0.918549       0.919704  \n",
       "11  0.429650  0.518672   0.518505      0.827854      0.838152       0.832271  \n",
       "12  0.637672  0.717404   0.717323      0.922971      0.920531       0.921517  \n",
       "17  0.628194  0.708931   0.708699      0.920939      0.917830       0.919140  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_qa2d(result_jsonls):\n",
    "    data = []\n",
    "    for rjsonl in result_jsonls:\n",
    "        data += read_jsonl(rjsonl)\n",
    "    # for d in data:\n",
    "    #     t = d[\"eval\"][\"bert_score_R1\"]\n",
    "    #     d[\"eval\"][\"bert_score_R\"] = t\n",
    "    #     del d[\"eval\"][\"bert_score_R1\"]\n",
    "    # write_jsonl(result_jsonls[0], data)\n",
    "    # return\n",
    "    df = pd.DataFrame(data)\n",
    "    models = ['/'.join(m.split(\"/\")[-3:]) for m in df.model]\n",
    "    df[\"model\"] = models\n",
    "    df[\"rouge1\"] = [e[\"rouge1\"] for e in df[\"eval\"]]\n",
    "    df[\"rouge2\"] = [e[\"rouge2\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeL\"] = [e[\"rougeL\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeLsum\"] = [e[\"rougeLsum\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_P\"] = [e[\"bert_score_P\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_R\"] = [e[\"bert_score_R\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_F1\"] = [e[\"bert_score_F1\"] for e in df[\"eval\"]]\n",
    "    df = df[[\"lang\", \"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\", \"bert_score_P\", \"bert_score_R\", \"bert_score_F1\"]]\n",
    "    df.sort_values(\"lang\", inplace=True)\n",
    "    return df\n",
    "\n",
    "df = compare_results_qa2d([\n",
    "    \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/results.jsonl\"\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_jsonl(\"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qacg/google/mt5_results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'lang': 'all',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/cs_en_pl_sk/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.8121849974992059,\n",
    "   'rouge2': 0.6774419510196882,\n",
    "   'rougeL': 0.7497730778117646,\n",
    "   'rougeLsum': 0.7497340248321841}},\n",
    " {'lang': 'cs_CZ',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/cs/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7783607331568722,\n",
    "   'rouge2': 0.6231575608427122,\n",
    "   'rougeL': 0.7039034412670073,\n",
    "   'rougeLsum': 0.703985133472832}},\n",
    " {'lang': 'en_US',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/en/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.9333374676443688,\n",
    "   'rouge2': 0.8544504708653158,\n",
    "   'rougeL': 0.88537866791236,\n",
    "   'rougeLsum': 0.8855242981238776}},\n",
    " {'lang': 'pl_PL',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/pl/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7579418551444153,\n",
    "   'rouge2': 0.6037844541036594,\n",
    "   'rougeL': 0.70104065486047,\n",
    "   'rougeLsum': 0.7011065700120231}},\n",
    " {'lang': 'sk_SK',\n",
    "  'model': '/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all',\n",
    "  'data_file': '/mnt/data/factcheck/qa2d/sk/dev.jsonl',\n",
    "  'rouge': {'rouge1': 0.7796807605964733,\n",
    "   'rouge2': 0.6282711920363941,\n",
    "   'rougeL': 0.7087832206401827,\n",
    "   'rougeLsum': 0.7089273080145163}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-26000\")\n",
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=\"cs_CZ\", fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proč organismy dědí vlastnosti svých rodičů?\n",
      "buňky potomků obsahují kopie genů z buněk jejich rodičů\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['organismy dědí vlastnosti svých rodičů, protože buňky potomků obsahují kopie genů z buněk jejich rodičů.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    model_inputs = {k: model_inputs[k].to(\"cuda\") for k in model_inputs.keys()}\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[6]\n",
    "question = sample[\"question\"]\n",
    "answer = sample[\"answer\"]\n",
    "# question = \"V kolika letech zemřel Petr?\"\n",
    "# answer = \"25\"\n",
    "print(textwrap.fill(question))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflarge",
   "language": "python",
   "name": "hflarge"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

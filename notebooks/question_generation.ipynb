{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "import unicodedata\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "import stanza\n",
    "# stanza.download(\"en\")\n",
    "\n",
    "sys.path.append('Claim_Generation')\n",
    "from T5_QG import pipeline\n",
    "from distractor_generation import Distractor_Generation\n",
    "\n",
    "sys.path.append('Models')\n",
    "from arguments import ModelArguments, DataTrainingArguments\n",
    "from load import load_tokenizer_and_model, find_last_checkpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares data to train QG models for different languages.\n",
    "The paper used T5 model from here: https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_squad(fsrc, fdst):\n",
    "    # converts SQUAD format to \"linear\" JSONL usable for training seq2seq model \n",
    "    data = read_json(fsrc)[\"data\"]\n",
    "    records = []\n",
    "    for rec in tqdm(data):\n",
    "        title = unicodedata.normalize(\"NFC\", rec[\"title\"])\n",
    "        for par in rec[\"paragraphs\"]:\n",
    "            context = unicodedata.normalize(\"NFC\", par[\"context\"])\n",
    "            for qas in par[\"qas\"]:\n",
    "                answer_set = set()\n",
    "                for ans in qas[\"answers\"]:\n",
    "                    ans = ans[\"text\"]\n",
    "                    if ans[-1] in [\".\", \",\"]:\n",
    "                        ans = ans[:-1]\n",
    "                    answer_set.add(ans)\n",
    "                answers = sorted(list(answer_set))\n",
    "                for answer in answers:\n",
    "                    question = qas[\"question\"].strip()\n",
    "                    question = question[0].upper() + question[1:]\n",
    "                    question = question.replace(\"  \", \" \")\n",
    "                    if not (question.endswith(\"?\") or question.endswith('?\"')):\n",
    "                        if not question.lower().startswith(\"name\"):\n",
    "                            if question[-1] in [\".\", \":\", \">\", \"/\"]: # Probably wrong parsing of original data\n",
    "                                question = question[:-1] + \"?\"\n",
    "                            else:\n",
    "                                question += \"?\"\n",
    "                    question = unicodedata.normalize(\"NFC\", question)\n",
    "                    answer = unicodedata.normalize(\"NFC\", answer)\n",
    "                    print(question)\n",
    "                    records.append({\"title\": title, \"context\": context, \"question\": question, \"answer\": answer})\n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "SQUAD_ROOT = Path(\"/mnt/data/factcheck/squad/squad-cs\")\n",
    "QG_ROOT = Path(\"/mnt/data/factcheck/qg/squad-cs\")\n",
    "\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, \"dev-v1.1.json\"), Path(QG_ROOT, \"dev-v1.1.jsonl\"))\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, \"train-v1.1.json\"), Path(QG_ROOT, \"train-v1.1.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-32000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=\"cs_CZ\", fp16=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_jsonl(\"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 byl zápas amerického fotbalu, který určil šampiona Národní fotbalové ligy (NFL) pro sezónu 2015. Šampion Americké fotbalové konference (AFC) Denver Broncos porazil šampiona Národní fotbalové konference (NFC) Carolinu Panthers 24:10 a získal třetí titul v Super Bowlu. Zápas se hrál 7. února 2016 na Leviho stadionu v San Francisco Bay Area v Santa Claře v Kalifornii. Protože se jednalo o 50. Super Bowl, liga zdůrazňovala \"zlaté výročí\" různými iniciativami se zlatou tematikou a také dočasně pozastavila tradici pojmenovávání každé hry Super Bowl římskými číslicemi (pod kterými by hra byla známá jako \"Super Bowl L\"), aby logo mohlo výrazně zobrazovat arabské číslice 50.',\n",
       " 'question': 'Který tým NFL reprezentoval AFC na Super Bowlu 50?',\n",
       " 'answer': 'Denver Broncos'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy\n",
      "Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura\n",
      "Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky\n",
      "v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo\n",
      "působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform\n",
      "mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově\n",
      "Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby\n",
      "Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s\n",
      "vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o\n",
      "pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s\n",
      "ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli\n",
      "kvůli vzdušnému poplachu v pátek na čas do hotelového krytu.\n",
      "Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a\n",
      "Slovenska poznamenala, že vysoce postavení zahraniční představitelé od\n",
      "začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\n",
      "NATO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Která agentura připomněla Pavlovo působení na vrcholné pozici?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[120]\n",
    "answer = sample[\"answer\"]\n",
    "context = \"Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli kvůli vzdušnému poplachu v pátek na čas do hotelového krytu. Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a Slovenska poznamenala, že vysoce postavení zahraniční představitelé od začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\"\n",
    "answer = \"NATO\"\n",
    "print(textwrap.fill(context))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fc_env_plight_env",
   "language": "python",
   "name": "fc_env_plight_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import bert_score\n",
    "\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.batch import batch_apply\n",
    "from aic_nlp_utils.encoding import nfc\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "\n",
    "%cd /home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n",
    "\n",
    "from zshot_fact_verify.models.arguments import ModelArguments, DataTrainingArguments\n",
    "from zshot_fact_verify.models.load import load_tokenizer_and_model, find_last_checkpoint\n",
    "from zshot_fact_verify.qg.question_generation import BatchQuestionGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares data to train QG models for different languages.\n",
    "The paper used T5 model from here: https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least sk-quad dataset has word-tokenized question, this should remove all unneeded whitespace\n",
    "def word_detokenize(txt: str) -> str:\n",
    "    def pair_detokenize(txt, s):\n",
    "        sub = \" \" + s + \" \"\n",
    "        idxs = [m.start() for m in re.finditer(sub, txt)]\n",
    "        if len(idxs) > 0 and len(idxs) % 2 == 0:\n",
    "            # ignore odd number of pair substrings\n",
    "            otxt = \"\"\n",
    "            first = 0\n",
    "            for i, idx in enumerate(idxs):\n",
    "                if i % 2 == 0:\n",
    "                    otxt += txt[first:idx] + ' ' + s\n",
    "                else:\n",
    "                    otxt += txt[first:idx] + s + ' '\n",
    "                first = idx + 3\n",
    "            otxt += txt[first:]\n",
    "            return otxt\n",
    "        else:\n",
    "            return txt\n",
    "    \n",
    "    txt = txt.replace(\"``\", '\"').replace(\"''\", '\"').replace(\",,\", '\"')\n",
    "    txt = pair_detokenize(txt, '\"')\n",
    "    txt = txt.replace(\" '\", \"'\")\n",
    "    txt = txt.replace(\" - \", \"-\")\n",
    "    txt = txt.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" ?\", \"?\").replace(\" :\", \":\").replace(\" ;\", \";\")\n",
    "    txt = txt.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_squad(fsrc, fdst, word_detokenize_questions=False):\n",
    "    # converts SQUAD format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers if Squad 2.0 is given\n",
    "    data = read_json(fsrc)[\"data\"]\n",
    "    records = []\n",
    "    for rec in tqdm(data):\n",
    "        title = nfc(rec[\"title\"])\n",
    "        for par in rec[\"paragraphs\"]:\n",
    "            context = nfc(par[\"context\"])\n",
    "            for qas in par[\"qas\"]:\n",
    "                if \"is_impossible\" in qas and qas[\"is_impossible\"]:\n",
    "                    continue\n",
    "                answer_set = set()\n",
    "                for ans in qas[\"answers\"]:\n",
    "                    ans = ans[\"text\"]\n",
    "                    if ans[-1] in [\".\", \",\"]:\n",
    "                        ans = ans[:-1]\n",
    "                    answer_set.add(ans)\n",
    "                answers = sorted(list(answer_set))\n",
    "                for answer in answers:\n",
    "                    question = qas[\"question\"].strip()\n",
    "                    question = question[0].upper() + question[1:]\n",
    "                    question = question.replace(\"  \", \" \")\n",
    "                    if word_detokenize_questions:\n",
    "                        question = word_detokenize(question)\n",
    "                    if not (question.endswith(\"?\") or question.endswith('?\"')):\n",
    "                        if not question.lower().startswith(\"name\"):\n",
    "                            if question[-1] in [\".\", \":\", \">\", \"/\"]: # Probably wrong parsing of original data\n",
    "                                question = question[:-1] + \"?\"\n",
    "                            else:\n",
    "                                question += \"?\"\n",
    "                    question = nfc(question)\n",
    "                    answer = nfc(answer)\n",
    "                    print(question)\n",
    "                    records.append({\"title\": title, \"context\": context, \"question\": question, \"answer\": answer})\n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "WORD_DETOKENIZE = False\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-cs', \"train-v1.1.json\", \"dev-v1.1.json\"\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-sk', \"train-230321.json\", \"dev-230321.json\"\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV, WORD_DETOKENIZE = 'sk-quad-220614', \"sk-quad-220614-train.json\", \"sk-quad-220614-dev.json\", True\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_DEV), Path(QG_ROOT, SQUAD_DEV), word_detokenize_questions=WORD_DETOKENIZE)\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_TRN), Path(QG_ROOT, SQUAD_TRN), word_detokenize_questions=WORD_DETOKENIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_csv_squad(fsrc, fdst):\n",
    "    # converts CSV SQUAD (e.g. SQUAD-pl) format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers\n",
    "    # title is missing in SQUAD-PL\n",
    "    df = pd.read_csv(fsrc)[[\"context\", \"question\", \"answer_text\"]]\n",
    "    print(f\"#records = {df.shape}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(f\"after drop #records = {df.shape}\")\n",
    "\n",
    "    records = []\n",
    "    for idx, r in tqdm(df.iterrows()):\n",
    "        title = None\n",
    "        context = nfc(str(r.context))\n",
    "        question = nfc(str(r.question))\n",
    "        answer = nfc(str(r.answer_text))\n",
    "        print(question)\n",
    "        # print(\" > \" + answer)\n",
    "        rec = {\"title\": title, \"context\": context, \"question\": question, \"answer\": answer}\n",
    "        records.append(rec)\n",
    "  \n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-pl', \"train\", \"test\"\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_DEV}.csv\"), Path(QG_ROOT, f\"{SQUAD_DEV}.jsonl\"))\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_TRN}.csv\"), Path(QG_ROOT, f\"{SQUAD_TRN}.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SQUAD Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 252281 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\n",
      "writing 40933 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\n"
     ]
    }
   ],
   "source": [
    "def combine_squads(split_files, out_file, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for sfile in split_files:\n",
    "        assert len(sfile.items()) == 1\n",
    "        for lang, path_ in sfile.items():\n",
    "            pass\n",
    "        split = read_jsonl(path_)\n",
    "        for s in split:\n",
    "            s[\"lang\"] = lang\n",
    "        data += split\n",
    "    rng.shuffle(data)\n",
    "    print(f\"writing {len(data)} records to {out_file}\")\n",
    "    write_jsonl(out_file, data, mkdir=True)\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/train-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/train-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/train.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-train.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\")\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/dev-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation by ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=True, device=\"cuda\"):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = model_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = model_inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "def predict_original_paper(data):\n",
    "    from zshot_fact_verify.claim_generation.T5_QG import pipeline\n",
    "    qg_nlp = pipeline(\"question-generation\", model='valhalla/t5-base-qg-hl', qg_format=\"highlight\", gpu_index=0)\n",
    "    \n",
    "    def predict_batch(data): \n",
    "        sources = [s[\"context\"] for s in data]\n",
    "        answers = [s[\"answer\"] for s in data]\n",
    "        Y = qg_nlp.batch_qg_with_answer(sources, answers)\n",
    "        return Y\n",
    "    \n",
    "    Y = batch_apply(predict_batch, data, batch_size=32, show_progress=True)\n",
    "    Y = [y[\"question\"] for y in Y]\n",
    "    T = [s[\"question\"] for s in data]\n",
    "    return Y, T\n",
    "\n",
    "def predict_split(model, tokenizer, data, batch_size=128):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"</s>\" + sample[\"context\"]) for sample in data]\n",
    "    pfunc = lambda batch: predict(model, tokenizer, batch)\n",
    "    Y = batch_apply(pfunc, X, batch_size=batch_size, show_progress=True)\n",
    "    T = [nfc(sample[\"question\"]) for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_rouge(Y, T):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(predictions=Y, references=T)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_quality(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        model_name = cfg[\"model\"]\n",
    "\n",
    "        if model_name == \"original\":\n",
    "            print(f\"lang: {lang}, model: ORIGINAL, data file: {data_file}\")\n",
    "            data = read_jsonl(data_file)\n",
    "            print(f\"  loaded {len(data)} samples\")\n",
    "            Y, T = predict_original_paper(data)\n",
    "        else:\n",
    "            model_short = \"/\".join(Path(model_name).parts[8:])\n",
    "            print(f\"lang: {lang}, model: {model_short}, data file: {data_file}\")\n",
    "\n",
    "            data = read_jsonl(data_file)\n",
    "            print(f\"  loaded {len(data)} samples\")\n",
    "            \n",
    "            model_args = ModelArguments(model_name_or_path=model_name)\n",
    "            tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n",
    "            model.to(\"cuda\")\n",
    "            model.eval();\n",
    "\n",
    "            Y, T = predict_split(model, tokenizer, data, batch_size=32)\n",
    "\n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: pl_PL, model: qg/google/mt5-large_pl, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00803375244140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d904cafd7c42e9820b3aadab8b635f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.37488054319641706, 'rouge2': 0.2138141866465533, 'rougeL': 0.3587911539945141, 'rougeLsum': 0.35832123857523335, 'bert_score_P': 0.8176380395889282, 'bert_score_R': 0.8090795874595642, 'bert_score_F1': 0.8125781416893005}\n",
      "lang: sk_SK, model: qg/google/mt5-large_sk/checkpoint-61000, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008040189743041992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb420ea553f433e82e443b5a8bbb53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.6171535214446101, 'rouge2': 0.4522694598934476, 'rougeL': 0.5945420489207971, 'rougeLsum': 0.5946052945286857, 'bert_score_P': 0.871673583984375, 'bert_score_R': 0.8658138513565063, 'bert_score_F1': 0.8678244948387146}\n",
      "lang: cs_CZ, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007961750030517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d3beed0634fe3bafa312edbf8e8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3708815086247411, 'rouge2': 0.1918320137868037, 'rougeL': 0.3460518595746516, 'rougeLsum': 0.3460155261032911, 'bert_score_P': 0.807235598564148, 'bert_score_R': 0.7936057448387146, 'bert_score_F1': 0.799572229385376}\n",
      "lang: en_US, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008162975311279297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa0112648446a0a368c3c984da921a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.4971248205606317, 'rouge2': 0.2780295951076388, 'rougeL': 0.46379181760387117, 'rougeLsum': 0.46381832576928517, 'bert_score_P': 0.8460949063301086, 'bert_score_R': 0.8336578607559204, 'bert_score_F1': 0.8391814827919006}\n",
      "lang: pl_PL, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008262157440185547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9478a649522b4073975f18b2cd53abd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3717682297658417, 'rouge2': 0.20860462247647032, 'rougeL': 0.35546015030178746, 'rougeLsum': 0.3553079250726834, 'bert_score_P': 0.8180533051490784, 'bert_score_R': 0.8055732250213623, 'bert_score_F1': 0.8110008239746094}\n",
      "lang: sk_SK, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00823521614074707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090069705de94b5ab15a0977366712af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.612123392896875, 'rouge2': 0.44658048499923364, 'rougeL': 0.5897836393029163, 'rougeLsum': 0.5900234805856639, 'bert_score_P': 0.8711510896682739, 'bert_score_R': 0.8627465963363647, 'bert_score_F1': 0.8660293221473694}\n"
     ]
    }
   ],
   "source": [
    "LANG = \"all\"\n",
    "LANG_SHORT = \"all\"\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_all/checkpoint-126000\"\n",
    "MODEL_NAME_CS = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_cs\" # FINAL \n",
    "MODEL_NAME_EN = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_en/checkpoint-64000\" # FINAL\n",
    "MODEL_NAME_PL = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_pl\" # FINAL\n",
    "MODEL_NAME_SK = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk/checkpoint-61000\" # FINAL\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK},\n",
    "    \n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL}, # NOT USED\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: experiments/qg/google/umt5-base_cs_CZ, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008320808410644531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c24932c68a5404b8fd32b9e3e9223a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3382812891335044, 'rouge2': 0.1656928084780808, 'rougeL': 0.3154058686951723, 'rougeLsum': 0.3154952471415421, 'bert_score_P': 0.7982181310653687, 'bert_score_R': 0.7836409211158752, 'bert_score_F1': 0.7900723814964294}\n",
      "lang: en_US, model: experiments/qg/google/umt5-base_en_US, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008389472961425781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b76276bdfa54be68d1f474c1a377bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.4803576161922338, 'rouge2': 0.26163355416835743, 'rougeL': 0.44866181202066013, 'rougeLsum': 0.4486326232848925, 'bert_score_P': 0.8420814871788025, 'bert_score_R': 0.8275054693222046, 'bert_score_F1': 0.8340489268302917}\n",
      "lang: pl_PL, model: experiments/qg/google/umt5-base_pl_PL, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008540868759155273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5132f615f0ad427785d826064359658d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3121625460931829, 'rouge2': 0.16462217627122833, 'rougeL': 0.2969682902766667, 'rougeLsum': 0.29683810731226695, 'bert_score_P': 0.8020727038383484, 'bert_score_R': 0.7883787155151367, 'bert_score_F1': 0.7943432331085205}\n",
      "lang: sk_SK, model: experiments/qg/google/umt5-base_sk_SK, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009338855743408203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623566890f73480bae772e5a99bf2488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.5825928038968479, 'rouge2': 0.4170115077812878, 'rougeL': 0.5606353587407773, 'rougeLsum': 0.5607869963702234, 'bert_score_P': 0.8632833957672119, 'bert_score_R': 0.8517776727676392, 'bert_score_F1': 0.8565813899040222}\n",
      "lang: cs_CZ, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008852481842041016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc0c584a82045edbdc694086daf7aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.35302872397920193, 'rouge2': 0.17738190137332735, 'rougeL': 0.32914259636287213, 'rougeLsum': 0.32920015243461415, 'bert_score_P': 0.8018673062324524, 'bert_score_R': 0.7882830500602722, 'bert_score_F1': 0.7942251563072205}\n",
      "lang: en_US, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00879526138305664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2db40c7ff14f7d91bba806e9e9459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.486302119720683, 'rouge2': 0.26812704244115926, 'rougeL': 0.4538395584860664, 'rougeLsum': 0.45384665783885525, 'bert_score_P': 0.8427534103393555, 'bert_score_R': 0.8297354578971863, 'bert_score_F1': 0.8355132937431335}\n",
      "lang: pl_PL, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008057594299316406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594c15ddd4184fb1868852ae9413468f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3639035589476781, 'rouge2': 0.20241942329968257, 'rougeL': 0.3483770292382762, 'rougeLsum': 0.3484797173067946, 'bert_score_P': 0.8161351680755615, 'bert_score_R': 0.8023266196250916, 'bert_score_F1': 0.8083663582801819}\n",
      "lang: sk_SK, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00898432731628418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ca930a6d904cf8bc39b2aa29c6214b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.5935037219019206, 'rouge2': 0.4272806506920769, 'rougeL': 0.5710327764377565, 'rougeLsum': 0.5710777537603315, 'bert_score_P': 0.866708517074585, 'bert_score_R': 0.8554693460464478, 'bert_score_F1': 0.8601471781730652}\n"
     ]
    }
   ],
   "source": [
    "# LANG = \"all\"\n",
    "# LANG_SHORT = \"all\"\n",
    "# QA2Ds were here!\n",
    "# MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all\"\n",
    "# MODEL_NAME_CS = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_cs_CZ\" # FINAL \n",
    "# MODEL_NAME_EN = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_en_US\" # FINAL\n",
    "# MODEL_NAME_PL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_pl_PL\" # FINAL\n",
    "# MODEL_NAME_SK = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_sk_SK\" # FINAL\n",
    "\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_all\"\n",
    "MODEL_NAME_CS = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_cs_CZ\" # FINAL \n",
    "MODEL_NAME_EN = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_en_US\" # FINAL\n",
    "MODEL_NAME_PL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_pl_PL\" # FINAL\n",
    "MODEL_NAME_SK = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_sk_SK\" # FINAL\n",
    "\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK}, # done\n",
    "    \n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL}, # missing!\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: ORIGINAL, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565, and set the legacy attribute accordingly.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00919485092163086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333cc23b3e3d4fb5b0636846979c5c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.09841955317631386, 'rouge2': 0.02848823438655762, 'rougeL': 0.09185948321821162, 'rougeLsum': 0.09185807029510903, 'bert_score_P': 0.6930422782897949, 'bert_score_R': 0.6721824407577515, 'bert_score_F1': 0.6818882822990417}\n",
      "lang: en_US, model: ORIGINAL, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008291006088256836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a4c4cd1bf44bb19ddf5ceb72cc8662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.49879397519319624, 'rouge2': 0.2840094098384389, 'rougeL': 0.4634463180184327, 'rougeLsum': 0.46345589394595976, 'bert_score_P': 0.839036226272583, 'bert_score_R': 0.8369964361190796, 'bert_score_F1': 0.8373371362686157}\n"
     ]
    }
   ],
   "source": [
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": \"original\", \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": \"original\", \"data_file\": DEV_FILE_EN},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bert_score_P</th>\n",
       "      <th>bert_score_R</th>\n",
       "      <th>bert_score_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/mt5-large_cs</td>\n",
       "      <td>37.288131</td>\n",
       "      <td>19.425672</td>\n",
       "      <td>34.744723</td>\n",
       "      <td>34.733320</td>\n",
       "      <td>80.542296</td>\n",
       "      <td>79.557836</td>\n",
       "      <td>79.971039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>35.302872</td>\n",
       "      <td>17.738190</td>\n",
       "      <td>32.914260</td>\n",
       "      <td>32.920015</td>\n",
       "      <td>80.186731</td>\n",
       "      <td>78.828305</td>\n",
       "      <td>79.422516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>original</td>\n",
       "      <td>9.841955</td>\n",
       "      <td>2.848823</td>\n",
       "      <td>9.185948</td>\n",
       "      <td>9.185807</td>\n",
       "      <td>69.304228</td>\n",
       "      <td>67.218244</td>\n",
       "      <td>68.188828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>37.088151</td>\n",
       "      <td>19.183201</td>\n",
       "      <td>34.605186</td>\n",
       "      <td>34.601553</td>\n",
       "      <td>80.723560</td>\n",
       "      <td>79.360574</td>\n",
       "      <td>79.957223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/umt5-base_cs_CZ</td>\n",
       "      <td>33.828129</td>\n",
       "      <td>16.569281</td>\n",
       "      <td>31.540587</td>\n",
       "      <td>31.549525</td>\n",
       "      <td>79.821813</td>\n",
       "      <td>78.364092</td>\n",
       "      <td>79.007238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>49.712482</td>\n",
       "      <td>27.802960</td>\n",
       "      <td>46.379182</td>\n",
       "      <td>46.381833</td>\n",
       "      <td>84.609491</td>\n",
       "      <td>83.365786</td>\n",
       "      <td>83.918148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qg/google/umt5-base_en_US</td>\n",
       "      <td>48.035762</td>\n",
       "      <td>26.163355</td>\n",
       "      <td>44.866181</td>\n",
       "      <td>44.863262</td>\n",
       "      <td>84.208149</td>\n",
       "      <td>82.750547</td>\n",
       "      <td>83.404893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_en/checkpoint-64000</td>\n",
       "      <td>49.954044</td>\n",
       "      <td>28.132323</td>\n",
       "      <td>46.689003</td>\n",
       "      <td>46.679203</td>\n",
       "      <td>84.717369</td>\n",
       "      <td>83.349091</td>\n",
       "      <td>83.961731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>48.630212</td>\n",
       "      <td>26.812704</td>\n",
       "      <td>45.383956</td>\n",
       "      <td>45.384666</td>\n",
       "      <td>84.275341</td>\n",
       "      <td>82.973546</td>\n",
       "      <td>83.551329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en_US</td>\n",
       "      <td>original</td>\n",
       "      <td>49.879398</td>\n",
       "      <td>28.400941</td>\n",
       "      <td>46.344632</td>\n",
       "      <td>46.345589</td>\n",
       "      <td>83.903623</td>\n",
       "      <td>83.699644</td>\n",
       "      <td>83.733714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>37.176823</td>\n",
       "      <td>20.860462</td>\n",
       "      <td>35.546015</td>\n",
       "      <td>35.530793</td>\n",
       "      <td>81.805331</td>\n",
       "      <td>80.557323</td>\n",
       "      <td>81.100082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/mt5-large_pl</td>\n",
       "      <td>37.488054</td>\n",
       "      <td>21.381419</td>\n",
       "      <td>35.879115</td>\n",
       "      <td>35.832124</td>\n",
       "      <td>81.763804</td>\n",
       "      <td>80.907959</td>\n",
       "      <td>81.257814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/umt5-base_pl_PL</td>\n",
       "      <td>31.216255</td>\n",
       "      <td>16.462218</td>\n",
       "      <td>29.696829</td>\n",
       "      <td>29.683811</td>\n",
       "      <td>80.207270</td>\n",
       "      <td>78.837872</td>\n",
       "      <td>79.434323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>36.390356</td>\n",
       "      <td>20.241942</td>\n",
       "      <td>34.837703</td>\n",
       "      <td>34.847972</td>\n",
       "      <td>81.613517</td>\n",
       "      <td>80.232662</td>\n",
       "      <td>80.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>61.212339</td>\n",
       "      <td>44.658048</td>\n",
       "      <td>58.978364</td>\n",
       "      <td>59.002348</td>\n",
       "      <td>87.115109</td>\n",
       "      <td>86.274660</td>\n",
       "      <td>86.602932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qg/google/umt5-base_sk_SK</td>\n",
       "      <td>58.259280</td>\n",
       "      <td>41.701151</td>\n",
       "      <td>56.063536</td>\n",
       "      <td>56.078700</td>\n",
       "      <td>86.328340</td>\n",
       "      <td>85.177767</td>\n",
       "      <td>85.658139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>59.350372</td>\n",
       "      <td>42.728065</td>\n",
       "      <td>57.103278</td>\n",
       "      <td>57.107775</td>\n",
       "      <td>86.670852</td>\n",
       "      <td>85.546935</td>\n",
       "      <td>86.014718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_sk/checkpoint-61000</td>\n",
       "      <td>61.715352</td>\n",
       "      <td>45.226946</td>\n",
       "      <td>59.454205</td>\n",
       "      <td>59.460529</td>\n",
       "      <td>87.167358</td>\n",
       "      <td>86.581385</td>\n",
       "      <td>86.782449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang                                   model     rouge1     rouge2  \\\n",
       "0   cs_CZ                  qg/google/mt5-large_cs  37.288131  19.425672   \n",
       "12  cs_CZ                 qg/google/umt5-base_all  35.302872  17.738190   \n",
       "16  cs_CZ                                original   9.841955   2.848823   \n",
       "4   cs_CZ  google/mt5-large_all/checkpoint-126000  37.088151  19.183201   \n",
       "8   cs_CZ               qg/google/umt5-base_cs_CZ  33.828129  16.569281   \n",
       "5   en_US  google/mt5-large_all/checkpoint-126000  49.712482  27.802960   \n",
       "9   en_US               qg/google/umt5-base_en_US  48.035762  26.163355   \n",
       "1   en_US    google/mt5-large_en/checkpoint-64000  49.954044  28.132323   \n",
       "13  en_US                 qg/google/umt5-base_all  48.630212  26.812704   \n",
       "17  en_US                                original  49.879398  28.400941   \n",
       "6   pl_PL  google/mt5-large_all/checkpoint-126000  37.176823  20.860462   \n",
       "2   pl_PL                  qg/google/mt5-large_pl  37.488054  21.381419   \n",
       "10  pl_PL               qg/google/umt5-base_pl_PL  31.216255  16.462218   \n",
       "14  pl_PL                 qg/google/umt5-base_all  36.390356  20.241942   \n",
       "7   sk_SK  google/mt5-large_all/checkpoint-126000  61.212339  44.658048   \n",
       "11  sk_SK               qg/google/umt5-base_sk_SK  58.259280  41.701151   \n",
       "15  sk_SK                 qg/google/umt5-base_all  59.350372  42.728065   \n",
       "3   sk_SK    google/mt5-large_sk/checkpoint-61000  61.715352  45.226946   \n",
       "\n",
       "       rougeL  rougeLsum  bert_score_P  bert_score_R  bert_score_F1  \n",
       "0   34.744723  34.733320     80.542296     79.557836      79.971039  \n",
       "12  32.914260  32.920015     80.186731     78.828305      79.422516  \n",
       "16   9.185948   9.185807     69.304228     67.218244      68.188828  \n",
       "4   34.605186  34.601553     80.723560     79.360574      79.957223  \n",
       "8   31.540587  31.549525     79.821813     78.364092      79.007238  \n",
       "5   46.379182  46.381833     84.609491     83.365786      83.918148  \n",
       "9   44.866181  44.863262     84.208149     82.750547      83.404893  \n",
       "1   46.689003  46.679203     84.717369     83.349091      83.961731  \n",
       "13  45.383956  45.384666     84.275341     82.973546      83.551329  \n",
       "17  46.344632  46.345589     83.903623     83.699644      83.733714  \n",
       "6   35.546015  35.530793     81.805331     80.557323      81.100082  \n",
       "2   35.879115  35.832124     81.763804     80.907959      81.257814  \n",
       "10  29.696829  29.683811     80.207270     78.837872      79.434323  \n",
       "14  34.837703  34.847972     81.613517     80.232662      80.836636  \n",
       "7   58.978364  59.002348     87.115109     86.274660      86.602932  \n",
       "11  56.063536  56.078700     86.328340     85.177767      85.658139  \n",
       "15  57.103278  57.107775     86.670852     85.546935      86.014718  \n",
       "3   59.454205  59.460529     87.167358     86.581385      86.782449  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_qg(result_jsonls):\n",
    "    data = []\n",
    "    for rjsonl in result_jsonls:\n",
    "        data += read_jsonl(rjsonl)\n",
    "    # for d in data:\n",
    "    #     if \"bert_score_R1\" in d[\"eval\"]:\n",
    "    #         t = d[\"eval\"][\"bert_score_R1\"]\n",
    "    #         d[\"eval\"][\"bert_score_R\"] = t\n",
    "    #         del d[\"eval\"][\"bert_score_R1\"]\n",
    "    # write_jsonl(result_jsonls[0], data)\n",
    "    # return\n",
    "    df = pd.DataFrame(data)\n",
    "    models = ['/'.join(m.split(\"/\")[-3:]) for m in df.model]\n",
    "    df[\"model\"] = models\n",
    "    df[\"rouge1\"] = [100*e[\"rouge1\"] for e in df[\"eval\"]]\n",
    "    df[\"rouge2\"] = [100*e[\"rouge2\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeL\"] = [100*e[\"rougeL\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeLsum\"] = [100*e[\"rougeLsum\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_P\"] = [100*e[\"bert_score_P\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_R\"] = [100*e[\"bert_score_R\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_F1\"] = [100*e[\"bert_score_F1\"] for e in df[\"eval\"]]\n",
    "    df = df[[\"lang\", \"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\", \"bert_score_P\", \"bert_score_R\", \"bert_score_F1\"]]\n",
    "    df.sort_values(\"lang\", inplace=True)\n",
    "    return df\n",
    "\n",
    "df = compare_results_qg([\n",
    "    \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\"\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " lang &                                  model &  rouge1 &  rouge2 &  rougeL &  bert\\_score\\_F1 \\\\\n",
      "\\midrule\n",
      "cs\\_CZ &                 qg/google/mt5-large\\_cs &    37.3 &    19.4 &    34.7 &           80.0 \\\\\n",
      "cs\\_CZ &                               original &     9.8 &     2.8 &     9.2 &           68.2 \\\\\n",
      "cs\\_CZ & google/mt5-large\\_all/checkpoint-126000 &    37.1 &    19.2 &    34.6 &           80.0 \\\\\n",
      "en\\_US & google/mt5-large\\_all/checkpoint-126000 &    49.7 &    27.8 &    46.4 &           83.9 \\\\\n",
      "en\\_US &   google/mt5-large\\_en/checkpoint-64000 &    50.0 &    28.1 &    46.7 &           84.0 \\\\\n",
      "en\\_US &                               original &    49.9 &    28.4 &    46.3 &           83.7 \\\\\n",
      "pl\\_PL & google/mt5-large\\_all/checkpoint-126000 &    37.2 &    20.9 &    35.5 &           81.1 \\\\\n",
      "pl\\_PL &                 qg/google/mt5-large\\_pl &    37.5 &    21.4 &    35.9 &           81.3 \\\\\n",
      "sk\\_SK & google/mt5-large\\_all/checkpoint-126000 &    61.2 &    44.7 &    59.0 &           86.6 \\\\\n",
      "sk\\_SK &   google/mt5-large\\_sk/checkpoint-61000 &    61.7 &    45.2 &    59.5 &           86.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2005688/2262563657.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))\n"
     ]
    }
   ],
   "source": [
    "print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS\n",
    "`qg/ctu-aic/flan-t5-large_cs_CZ/bkp/checkpoint-12672`\n",
    "\n",
    "*{'rouge1': 0.12963591761229037, 'rouge2': 0.023885136378797505, 'rougeL': 0.12183362628568076, 'rougeLsum': 0.1217667170120719}*\n",
    "\n",
    "Wrong tokenization.\n",
    "\n",
    "`qg/google/mt5-large_cs_CZ/checkpoint-59000`\n",
    "\n",
    "*{'rouge1': 0.3694537189887302, 'rouge2': 0.19169694531279952, 'rougeL': 0.34545989041700687, 'rougeLsum': 0.34555287654344513}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ/bkp/checkpoint-6400`\n",
    "\n",
    "*{'rouge1': 0.30904739385202495, 'rouge2': 0.14175598892317176, 'rougeL': 0.2874681246496394, 'rougeLsum': 0.28755029622694217}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ`\n",
    "\n",
    "*{'rouge1': 0.3379285112695145, 'rouge2': 0.16586064794677036, 'rougeL': 0.3152727384483949, 'rougeLsum': 0.3154454957579359}*\n",
    "\n",
    "### EN\n",
    "\n",
    "`original`\n",
    "\n",
    "*{'rouge1': 0.4989229792773411, 'rouge2': 0.28414967309411343, 'rougeL': 0.4635031675966017, 'rougeLsum': 0.4634836172778146}*\n",
    "\n",
    "`qg/google/mt5-large_en/checkpoint-64000`\n",
    "\n",
    "**{'rouge1': 0.4995418652865221, 'rouge2': 0.2815535664262393, 'rougeL': 0.4668170545426994, 'rougeLsum': 0.46687703737445807}**\n",
    "\n",
    "`qg/google/flan-t5-large_en_US/checkpoint-7936`\n",
    "\n",
    "*{'rouge1': 0.5050762371759718, 'rouge2': 0.28730345133694524, 'rougeL': 0.4710796839809428, 'rougeLsum': 0.47103764958291705}*\n",
    "\n",
    "`qg/google/umt5-base_en_US`\n",
    "\n",
    "*{'rouge1': 0.48045112431026354, 'rouge2': 0.26173784145711765, 'rougeL': 0.4487262083667449, 'rougeLsum': 0.4487590621176192}*\n",
    "\n",
    "### PL\n",
    "\n",
    "`qg/google/mt5-large_pl/checkpoint-34000`\n",
    "\n",
    "*{'rouge1': 0.3670461463062099, 'rouge2': 0.20664767638201073, 'rougeL': 0.3513302909076887, 'rougeLsum': 0.3514851628255672}*\n",
    "\n",
    "`qg/google/flan-t5-large_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.2651964323903675, 'rouge2': 0.10999222537607427, 'rougeL': 0.25368293682015525, 'rougeLsum': 0.2532975070425204}*\n",
    "\n",
    "`qg/google/umt5-base_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.31209527473925364, 'rouge2': 0.16440549183090475, 'rougeL': 0.29680613676413997, 'rougeLsum': 0.29705324007033296}*\n",
    "\n",
    "### SK\n",
    "`qg/google/mt5-large_sk_SK/checkpoint-37000`\n",
    "\n",
    "*{'rouge1': 0.2947516032244862, 'rouge2': 0.13924328095469365, 'rougeL': 0.2711889534899373, 'rougeLsum': 0.2710563599995189}*\n",
    "\n",
    "`qg/google/umt5-base_sk_SK`\n",
    "*{'rouge1': 0.5825675978707048, 'rouge2': 0.41734228678000224, 'rougeL': 0.5607684287432402, 'rougeLsum': 0.560618385882808}*\n",
    "\n",
    "### ALL\n",
    "\n",
    "`qg/google/umt5-base_all`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4572821393722631, 'rouge2': 0.2663545003075309, 'rougeL': 0.43077904314996096, 'rougeLsum': 0.43072475188146}*\n",
    "\n",
    "**CS** *{'rouge1': 0.35290062436342096, 'rouge2': 0.17738150128215946, 'rougeL': 0.3292826941280448, 'rougeLsum': 0.3290628070321041}*\n",
    "\n",
    "**EN** *{'rouge1': 0.48636008671818154,'rouge2': 0.2681378422877396, 'rougeL': 0.4539385644052849, 'rougeLsum': 0.4539682258809208}*\n",
    "\n",
    "**PL** *{'rouge1': 0.36408309004184375, 'rouge2': 0.20234412375822144, 'rougeL': 0.3484808037947017, 'rougeLsum': 0.3484233231283168}*\n",
    "\n",
    "**SK** *{'rouge1': 0.5935977294706721, 'rouge2': 0.4272281779017747, 'rougeL': 0.5711202748270763, 'rougeLsum': 0.5709580363216058}*\n",
    "\n",
    "`qg/google/mt5-large_all/BKP/checkpoint-126000`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4712879903083035, 'rouge2': 0.2790771005345815,  'rougeL': 0.44412574432094815,  'rougeLsum': 0.4440181809982411}*\n",
    "\n",
    "**CS** **{'rouge1': 0.37076781953491367, 'rouge2': 0.19188317187558196, 'rougeL': 0.34603606602711284, 'rougeLsum': 0.3458732199471718}**\n",
    "\n",
    "**EN** *{'rouge1': 0.4972121341475896, 'rouge2': 0.27814731357909395, 'rougeL': 0.46391560371478174, 'rougeLsum': 0.46394229428970657}*\n",
    "\n",
    "**PL** **{'rouge1': 0.3717109027777702, 'rouge2': 0.20806629045849118, 'rougeL': 0.35534417379213407, 'rougeLsum': 0.35545025872361985}**\n",
    "\n",
    "**SK** **{'rouge1': 0.6120836094748034, 'rouge2': 0.4468872126953193, 'rougeL': 0.5898635208080331, 'rougeLsum': 0.5898424756234816}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for model inference\n",
    "see `scripts/wiki_qg.py` for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CZ\n",
    "lang = \"cs_CZ\"\n",
    "# model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-32000\")\n",
    "\n",
    "# SK\n",
    "lang = \"sk_SK\"\n",
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk_SK/checkpoint-37000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS\n",
    "# data = read_jsonl(\"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\")\n",
    "\n",
    "# SK\n",
    "data = read_jsonl(\"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Vysok gr (Laboreck vrchovina)',\n",
       " 'context': 'Cez vrch Vysok gr vedie hlavn  erven turistick znaka, ktor zrove vedie po hlavnom karpatskom hrebeni cez najvchodnej bod Slovenska  trojmedzie (1207.7 Mnm) na vrchu Kremenec (1221.0 Mnm) a prechdza po slovensko-poskej ttnej hranici cez viacero vrchov s viacermi panoramatickmi vyhliadkami, ako napr. Kamenn lka (1200.9 Mnm), Jarab skala (1199.0 Mnm), urkovec (1188.7 Mnm), Paa (1162.8 Mnm), alej cez Rusk sedlo (801.0 Mnm), vrchy Rypy (1002.7 Mnm), Strop, (1011.2 Mnm), erniny (929.4 Mnm), Laboreck priesmyk (684.0 Mnm) a k Duklianskemu priesmyku (502.0 Mnm).',\n",
       " 'question': 'Ak nadmorsk vku m vrch Kremenec?',\n",
       " 'answer': '1221.0 Mnm'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vzkaz na vojensk technice zaujal po sobotn sti Pavlovy nvtvy\n",
      "Ukrajiny nkter ukrajinsk mdia. Pe o nm tak kupkladu agentura\n",
      "Unian, kter zrove informuje o Pavlov setkn s ukrajinskmi vojky\n",
      "v Dnpropetrovsk oblasti, agentura Ukrinform, je pipomnla Pavlovo\n",
      "psoben na vrcholn pozici v NATO, nebo server Obozrevatel. Ukrinform\n",
      "mimo jin zaznamenal jednn prezidenta s mstnmi initeli o obnov\n",
      "Dnpropetrovsk oblasti, nad n esko pevzalo ztitu. Weby\n",
      "Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkn s\n",
      "vysdlenmi Ukrajinci. Ukrajinsk mdia informovala u dve o\n",
      "ptenm programu Pavla a aputov, krom jejich oficilnch setkn s\n",
      "ukrajinskmi initeli si povimla mimo jin faktu, e sttnci museli\n",
      "kvli vzdunmu poplachu v ptek na as do hotelovho krytu.\n",
      "Ukrajinska pravda v souvislosti s nvtvou prezident eska a\n",
      "Slovenska poznamenala, e vysoce postaven zahranin pedstavitel od\n",
      "zatku rusk invaze jen zdka zstali na Ukrajin pes noc.\n",
      "NATO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['V ktorom tte psobil prezident Pavlo Pavlov na vrcholnej pozicii?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[120]\n",
    "answer = sample[\"answer\"]\n",
    "context = \"Vzkaz na vojensk technice zaujal po sobotn sti Pavlovy nvtvy Ukrajiny nkter ukrajinsk mdia. Pe o nm tak kupkladu agentura Unian, kter zrove informuje o Pavlov setkn s ukrajinskmi vojky v Dnpropetrovsk oblasti, agentura Ukrinform, je pipomnla Pavlovo psoben na vrcholn pozici v NATO, nebo server Obozrevatel. Ukrinform mimo jin zaznamenal jednn prezidenta s mstnmi initeli o obnov Dnpropetrovsk oblasti, nad n esko pevzalo ztitu. Weby Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkn s vysdlenmi Ukrajinci. Ukrajinsk mdia informovala u dve o ptenm programu Pavla a aputov, krom jejich oficilnch setkn s ukrajinskmi initeli si povimla mimo jin faktu, e sttnci museli kvli vzdunmu poplachu v ptek na as do hotelovho krytu. Ukrajinska pravda v souvislosti s nvtvou prezident eska a Slovenska poznamenala, e vysoce postaven zahranin pedstavitel od zatku rusk invaze jen zdka zstali na Ukrajin pes noc.\"\n",
    "answer = \"NATO\"\n",
    "print(textwrap.fill(context))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32150, 1024)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "model_id = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "accents = \"\" # CS\n",
    "accents += \"\" # PL\n",
    "accents += \"\" # SK\n",
    "accents += accents.upper()\n",
    "accents = set(c for c in accents)\n",
    "new_tokens = accents - set(tokenizer.vocab.keys())\n",
    "\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53385a98a1e4eca9a5d2b8095d29e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008115768432617188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 3001279361,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806913f99a494f26bff1d0cd07d95828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016201257705688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b8ff0c1954808beb0a414dd7cda53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/44e85df0c017c2ee04a322a13ddd14d0674f357d', commit_message='Upload model', commit_description='', oid='44e85df0c017c2ee04a322a13ddd14d0674f357d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008070945739746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4969ea29d072489eb0b6448a8201b0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00809168815612793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "spiece.model",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dbb221150a46b1be926a0aef862f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/6e995ffb333de1a0238236976bc7a9271ddf1e3a', commit_message='Upload tokenizer', commit_description='', oid='6e995ffb333de1a0238236976bc7a9271ddf1e3a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nech ji h n saxofony  bl rozezvu s  d sn mi tny waltzu, tanga a quickstepu.</s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Nech ji hn saxofony bl rozezvu s dsnmi tny waltzu, tanga a quickstepu.\"\n",
    "ids = tokenizer(txt)[\"input_ids\"]\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1484,\n",
       " 524,\n",
       " 2,\n",
       " 3,\n",
       " 354,\n",
       " 23,\n",
       " 2,\n",
       " 3,\n",
       " 107,\n",
       " 2,\n",
       " 29,\n",
       " 154,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 226,\n",
       " 858,\n",
       " 106,\n",
       " 63,\n",
       " 3,\n",
       " 2,\n",
       " 2975,\n",
       " 115,\n",
       " 40,\n",
       " 2,\n",
       " 3,\n",
       " 9860,\n",
       " 457,\n",
       " 208,\n",
       " 76,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 2,\n",
       " 7,\n",
       " 29,\n",
       " 2,\n",
       " 51,\n",
       " 23,\n",
       " 3,\n",
       " 17,\n",
       " 15742,\n",
       " 63,\n",
       " 3,\n",
       " 5380,\n",
       " 17,\n",
       " 1000,\n",
       " 6,\n",
       " 3,\n",
       " 8967,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 1704,\n",
       " 7910,\n",
       " 76,\n",
       " 5,\n",
       " 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32100, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflarge",
   "language": "python",
   "name": "hflarge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

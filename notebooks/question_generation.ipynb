{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import bert_score\n",
    "\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.batch import batch_apply\n",
    "from aic_nlp_utils.encoding import nfc\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "\n",
    "%cd /home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n",
    "\n",
    "from zshot_fact_verify.models.arguments import ModelArguments, DataTrainingArguments\n",
    "from zshot_fact_verify.models.load import load_tokenizer_and_model, find_last_checkpoint\n",
    "from zshot_fact_verify.qg.question_generation import BatchQuestionGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares data to train QG models for different languages.\n",
    "The paper used T5 model from here: https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least sk-quad dataset has word-tokenized question, this should remove all unneeded whitespace\n",
    "def word_detokenize(txt: str) -> str:\n",
    "    def pair_detokenize(txt, s):\n",
    "        sub = \" \" + s + \" \"\n",
    "        idxs = [m.start() for m in re.finditer(sub, txt)]\n",
    "        if len(idxs) > 0 and len(idxs) % 2 == 0:\n",
    "            # ignore odd number of pair substrings\n",
    "            otxt = \"\"\n",
    "            first = 0\n",
    "            for i, idx in enumerate(idxs):\n",
    "                if i % 2 == 0:\n",
    "                    otxt += txt[first:idx] + ' ' + s\n",
    "                else:\n",
    "                    otxt += txt[first:idx] + s + ' '\n",
    "                first = idx + 3\n",
    "            otxt += txt[first:]\n",
    "            return otxt\n",
    "        else:\n",
    "            return txt\n",
    "    \n",
    "    txt = txt.replace(\"``\", '\"').replace(\"''\", '\"').replace(\",,\", '\"')\n",
    "    txt = pair_detokenize(txt, '\"')\n",
    "    txt = txt.replace(\" '\", \"'\")\n",
    "    txt = txt.replace(\" - \", \"-\")\n",
    "    txt = txt.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" ?\", \"?\").replace(\" :\", \":\").replace(\" ;\", \";\")\n",
    "    txt = txt.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_squad(fsrc, fdst, word_detokenize_questions=False):\n",
    "    # converts SQUAD format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers if Squad 2.0 is given\n",
    "    data = read_json(fsrc)[\"data\"]\n",
    "    records = []\n",
    "    for rec in tqdm(data):\n",
    "        title = nfc(rec[\"title\"])\n",
    "        for par in rec[\"paragraphs\"]:\n",
    "            context = nfc(par[\"context\"])\n",
    "            for qas in par[\"qas\"]:\n",
    "                if \"is_impossible\" in qas and qas[\"is_impossible\"]:\n",
    "                    continue\n",
    "                answer_set = set()\n",
    "                for ans in qas[\"answers\"]:\n",
    "                    ans = ans[\"text\"]\n",
    "                    if ans[-1] in [\".\", \",\"]:\n",
    "                        ans = ans[:-1]\n",
    "                    answer_set.add(ans)\n",
    "                answers = sorted(list(answer_set))\n",
    "                for answer in answers:\n",
    "                    question = qas[\"question\"].strip()\n",
    "                    question = question[0].upper() + question[1:]\n",
    "                    question = question.replace(\"  \", \" \")\n",
    "                    if word_detokenize_questions:\n",
    "                        question = word_detokenize(question)\n",
    "                    if not (question.endswith(\"?\") or question.endswith('?\"')):\n",
    "                        if not question.lower().startswith(\"name\"):\n",
    "                            if question[-1] in [\".\", \":\", \">\", \"/\"]: # Probably wrong parsing of original data\n",
    "                                question = question[:-1] + \"?\"\n",
    "                            else:\n",
    "                                question += \"?\"\n",
    "                    question = nfc(question)\n",
    "                    answer = nfc(answer)\n",
    "                    print(question)\n",
    "                    records.append({\"title\": title, \"context\": context, \"question\": question, \"answer\": answer})\n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "WORD_DETOKENIZE = False\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-cs', \"train-v1.1.json\", \"dev-v1.1.json\"\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-sk', \"train-230321.json\", \"dev-230321.json\"\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV, WORD_DETOKENIZE = 'sk-quad-220614', \"sk-quad-220614-train.json\", \"sk-quad-220614-dev.json\", True\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_DEV), Path(QG_ROOT, SQUAD_DEV), word_detokenize_questions=WORD_DETOKENIZE)\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_TRN), Path(QG_ROOT, SQUAD_TRN), word_detokenize_questions=WORD_DETOKENIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_csv_squad(fsrc, fdst):\n",
    "    # converts CSV SQUAD (e.g. SQUAD-pl) format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers\n",
    "    # title is missing in SQUAD-PL\n",
    "    df = pd.read_csv(fsrc)[[\"context\", \"question\", \"answer_text\"]]\n",
    "    print(f\"#records = {df.shape}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(f\"after drop #records = {df.shape}\")\n",
    "\n",
    "    records = []\n",
    "    for idx, r in tqdm(df.iterrows()):\n",
    "        title = None\n",
    "        context = nfc(str(r.context))\n",
    "        question = nfc(str(r.question))\n",
    "        answer = nfc(str(r.answer_text))\n",
    "        print(question)\n",
    "        # print(\" > \" + answer)\n",
    "        rec = {\"title\": title, \"context\": context, \"question\": question, \"answer\": answer}\n",
    "        records.append(rec)\n",
    "  \n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-pl', \"train\", \"test\"\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_DEV}.csv\"), Path(QG_ROOT, f\"{SQUAD_DEV}.jsonl\"))\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_TRN}.csv\"), Path(QG_ROOT, f\"{SQUAD_TRN}.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SQUAD Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 252281 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\n",
      "writing 40933 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\n"
     ]
    }
   ],
   "source": [
    "def combine_squads(split_files, out_file, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for sfile in split_files:\n",
    "        assert len(sfile.items()) == 1\n",
    "        for lang, path_ in sfile.items():\n",
    "            pass\n",
    "        split = read_jsonl(path_)\n",
    "        for s in split:\n",
    "            s[\"lang\"] = lang\n",
    "        data += split\n",
    "    rng.shuffle(data)\n",
    "    print(f\"writing {len(data)} records to {out_file}\")\n",
    "    write_jsonl(out_file, data, mkdir=True)\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/train-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/train-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/train.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-train.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\")\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/dev-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation by ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=True, device=\"cuda\"):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = model_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = model_inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "def predict_original_paper(data):\n",
    "    from zshot_fact_verify.claim_generation.T5_QG import pipeline\n",
    "    qg_nlp = pipeline(\"question-generation\", model='valhalla/t5-base-qg-hl', qg_format=\"highlight\", gpu_index=0)\n",
    "    \n",
    "    def predict_batch(data): \n",
    "        sources = [s[\"context\"] for s in data]\n",
    "        answers = [s[\"answer\"] for s in data]\n",
    "        Y = qg_nlp.batch_qg_with_answer(sources, answers)\n",
    "        return Y\n",
    "    \n",
    "    Y = batch_apply(predict_batch, data, batch_size=32, show_progress=True)\n",
    "    Y = [y[\"question\"] for y in Y]\n",
    "    T = [s[\"question\"] for s in data]\n",
    "    return Y, T\n",
    "\n",
    "def predict_split(model, tokenizer, data, batch_size=128):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"</s>\" + sample[\"context\"]) for sample in data]\n",
    "    pfunc = lambda batch: predict(model, tokenizer, batch)\n",
    "    Y = batch_apply(pfunc, X, batch_size=batch_size, show_progress=True)\n",
    "    T = [nfc(sample[\"question\"]) for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_rouge(Y, T):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(predictions=Y, references=T)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_quality(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        model_name = cfg[\"model\"]\n",
    "\n",
    "        if model_name == \"original\":\n",
    "            print(f\"lang: {lang}, model: ORIGINAL, data file: {data_file}\")\n",
    "            data = read_jsonl(data_file)\n",
    "            print(f\"  loaded {len(data)} samples\")\n",
    "            Y, T = predict_original_paper(data)\n",
    "        else:\n",
    "            model_short = \"/\".join(Path(model_name).parts[8:])\n",
    "            print(f\"lang: {lang}, model: {model_short}, data file: {data_file}\")\n",
    "\n",
    "            data = read_jsonl(data_file)\n",
    "            print(f\"  loaded {len(data)} samples\")\n",
    "            \n",
    "            model_args = ModelArguments(model_name_or_path=model_name)\n",
    "            tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n",
    "            model.to(\"cuda\")\n",
    "            model.eval();\n",
    "\n",
    "            Y, T = predict_split(model, tokenizer, data, batch_size=32)\n",
    "\n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: pl_PL, model: qg/google/mt5-large_pl, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00803375244140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d904cafd7c42e9820b3aadab8b635f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.37488054319641706, 'rouge2': 0.2138141866465533, 'rougeL': 0.3587911539945141, 'rougeLsum': 0.35832123857523335, 'bert_score_P': 0.8176380395889282, 'bert_score_R': 0.8090795874595642, 'bert_score_F1': 0.8125781416893005}\n",
      "lang: sk_SK, model: qg/google/mt5-large_sk/checkpoint-61000, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008040189743041992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb420ea553f433e82e443b5a8bbb53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.6171535214446101, 'rouge2': 0.4522694598934476, 'rougeL': 0.5945420489207971, 'rougeLsum': 0.5946052945286857, 'bert_score_P': 0.871673583984375, 'bert_score_R': 0.8658138513565063, 'bert_score_F1': 0.8678244948387146}\n",
      "lang: cs_CZ, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007961750030517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d3beed0634fe3bafa312edbf8e8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3708815086247411, 'rouge2': 0.1918320137868037, 'rougeL': 0.3460518595746516, 'rougeLsum': 0.3460155261032911, 'bert_score_P': 0.807235598564148, 'bert_score_R': 0.7936057448387146, 'bert_score_F1': 0.799572229385376}\n",
      "lang: en_US, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008162975311279297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa0112648446a0a368c3c984da921a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.4971248205606317, 'rouge2': 0.2780295951076388, 'rougeL': 0.46379181760387117, 'rougeLsum': 0.46381832576928517, 'bert_score_P': 0.8460949063301086, 'bert_score_R': 0.8336578607559204, 'bert_score_F1': 0.8391814827919006}\n",
      "lang: pl_PL, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008262157440185547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9478a649522b4073975f18b2cd53abd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3717682297658417, 'rouge2': 0.20860462247647032, 'rougeL': 0.35546015030178746, 'rougeLsum': 0.3553079250726834, 'bert_score_P': 0.8180533051490784, 'bert_score_R': 0.8055732250213623, 'bert_score_F1': 0.8110008239746094}\n",
      "lang: sk_SK, model: experiments/qg/google/mt5-large_all/checkpoint-126000, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00823521614074707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090069705de94b5ab15a0977366712af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.612123392896875, 'rouge2': 0.44658048499923364, 'rougeL': 0.5897836393029163, 'rougeLsum': 0.5900234805856639, 'bert_score_P': 0.8711510896682739, 'bert_score_R': 0.8627465963363647, 'bert_score_F1': 0.8660293221473694}\n"
     ]
    }
   ],
   "source": [
    "LANG = \"all\"\n",
    "LANG_SHORT = \"all\"\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_all/checkpoint-126000\"\n",
    "MODEL_NAME_CS = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_cs\" # FINAL \n",
    "MODEL_NAME_EN = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_en/checkpoint-64000\" # FINAL\n",
    "MODEL_NAME_PL = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_pl\" # FINAL\n",
    "MODEL_NAME_SK = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk/checkpoint-61000\" # FINAL\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK},\n",
    "    \n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL}, # NOT USED\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: experiments/qg/google/umt5-base_cs_CZ, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008320808410644531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c24932c68a5404b8fd32b9e3e9223a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3382812891335044, 'rouge2': 0.1656928084780808, 'rougeL': 0.3154058686951723, 'rougeLsum': 0.3154952471415421, 'bert_score_P': 0.7982181310653687, 'bert_score_R': 0.7836409211158752, 'bert_score_F1': 0.7900723814964294}\n",
      "lang: en_US, model: experiments/qg/google/umt5-base_en_US, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008389472961425781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b76276bdfa54be68d1f474c1a377bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.4803576161922338, 'rouge2': 0.26163355416835743, 'rougeL': 0.44866181202066013, 'rougeLsum': 0.4486326232848925, 'bert_score_P': 0.8420814871788025, 'bert_score_R': 0.8275054693222046, 'bert_score_F1': 0.8340489268302917}\n",
      "lang: pl_PL, model: experiments/qg/google/umt5-base_pl_PL, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008540868759155273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5132f615f0ad427785d826064359658d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3121625460931829, 'rouge2': 0.16462217627122833, 'rougeL': 0.2969682902766667, 'rougeLsum': 0.29683810731226695, 'bert_score_P': 0.8020727038383484, 'bert_score_R': 0.7883787155151367, 'bert_score_F1': 0.7943432331085205}\n",
      "lang: sk_SK, model: experiments/qg/google/umt5-base_sk_SK, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009338855743408203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623566890f73480bae772e5a99bf2488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.5825928038968479, 'rouge2': 0.4170115077812878, 'rougeL': 0.5606353587407773, 'rougeLsum': 0.5607869963702234, 'bert_score_P': 0.8632833957672119, 'bert_score_R': 0.8517776727676392, 'bert_score_F1': 0.8565813899040222}\n",
      "lang: cs_CZ, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008852481842041016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc0c584a82045edbdc694086daf7aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.35302872397920193, 'rouge2': 0.17738190137332735, 'rougeL': 0.32914259636287213, 'rougeLsum': 0.32920015243461415, 'bert_score_P': 0.8018673062324524, 'bert_score_R': 0.7882830500602722, 'bert_score_F1': 0.7942251563072205}\n",
      "lang: en_US, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00879526138305664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2db40c7ff14f7d91bba806e9e9459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.486302119720683, 'rouge2': 0.26812704244115926, 'rougeL': 0.4538395584860664, 'rougeLsum': 0.45384665783885525, 'bert_score_P': 0.8427534103393555, 'bert_score_R': 0.8297354578971863, 'bert_score_F1': 0.8355132937431335}\n",
      "lang: pl_PL, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008057594299316406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594c15ddd4184fb1868852ae9413468f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.3639035589476781, 'rouge2': 0.20241942329968257, 'rougeL': 0.3483770292382762, 'rougeLsum': 0.3484797173067946, 'bert_score_P': 0.8161351680755615, 'bert_score_R': 0.8023266196250916, 'bert_score_F1': 0.8083663582801819}\n",
      "lang: sk_SK, model: experiments/qg/google/umt5-base_all, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00898432731628418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ca930a6d904cf8bc39b2aa29c6214b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.5935037219019206, 'rouge2': 0.4272806506920769, 'rougeL': 0.5710327764377565, 'rougeLsum': 0.5710777537603315, 'bert_score_P': 0.866708517074585, 'bert_score_R': 0.8554693460464478, 'bert_score_F1': 0.8601471781730652}\n"
     ]
    }
   ],
   "source": [
    "# LANG = \"all\"\n",
    "# LANG_SHORT = \"all\"\n",
    "# QA2Ds were here!\n",
    "# MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all\"\n",
    "# MODEL_NAME_CS = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_cs_CZ\" # FINAL \n",
    "# MODEL_NAME_EN = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_en_US\" # FINAL\n",
    "# MODEL_NAME_PL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_pl_PL\" # FINAL\n",
    "# MODEL_NAME_SK = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_sk_SK\" # FINAL\n",
    "\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_all\"\n",
    "MODEL_NAME_CS = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_cs_CZ\" # FINAL \n",
    "MODEL_NAME_EN = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_en_US\" # FINAL\n",
    "MODEL_NAME_PL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_pl_PL\" # FINAL\n",
    "MODEL_NAME_SK = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_sk_SK\" # FINAL\n",
    "\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK}, # done\n",
    "    \n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL}, # missing!\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: ORIGINAL, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565, and set the legacy attribute accordingly.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00919485092163086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333cc23b3e3d4fb5b0636846979c5c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.09841955317631386, 'rouge2': 0.02848823438655762, 'rougeL': 0.09185948321821162, 'rougeLsum': 0.09185807029510903, 'bert_score_P': 0.6930422782897949, 'bert_score_R': 0.6721824407577515, 'bert_score_F1': 0.6818882822990417}\n",
      "lang: en_US, model: ORIGINAL, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008291006088256836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a4c4cd1bf44bb19ddf5ceb72cc8662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.49879397519319624, 'rouge2': 0.2840094098384389, 'rougeL': 0.4634463180184327, 'rougeLsum': 0.46345589394595976, 'bert_score_P': 0.839036226272583, 'bert_score_R': 0.8369964361190796, 'bert_score_F1': 0.8373371362686157}\n"
     ]
    }
   ],
   "source": [
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": \"original\", \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": \"original\", \"data_file\": DEV_FILE_EN},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bert_score_P</th>\n",
       "      <th>bert_score_R</th>\n",
       "      <th>bert_score_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/mt5-large_cs</td>\n",
       "      <td>37.288131</td>\n",
       "      <td>19.425672</td>\n",
       "      <td>34.744723</td>\n",
       "      <td>34.733320</td>\n",
       "      <td>80.542296</td>\n",
       "      <td>79.557836</td>\n",
       "      <td>79.971039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>35.302872</td>\n",
       "      <td>17.738190</td>\n",
       "      <td>32.914260</td>\n",
       "      <td>32.920015</td>\n",
       "      <td>80.186731</td>\n",
       "      <td>78.828305</td>\n",
       "      <td>79.422516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>original</td>\n",
       "      <td>9.841955</td>\n",
       "      <td>2.848823</td>\n",
       "      <td>9.185948</td>\n",
       "      <td>9.185807</td>\n",
       "      <td>69.304228</td>\n",
       "      <td>67.218244</td>\n",
       "      <td>68.188828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>37.088151</td>\n",
       "      <td>19.183201</td>\n",
       "      <td>34.605186</td>\n",
       "      <td>34.601553</td>\n",
       "      <td>80.723560</td>\n",
       "      <td>79.360574</td>\n",
       "      <td>79.957223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/umt5-base_cs_CZ</td>\n",
       "      <td>33.828129</td>\n",
       "      <td>16.569281</td>\n",
       "      <td>31.540587</td>\n",
       "      <td>31.549525</td>\n",
       "      <td>79.821813</td>\n",
       "      <td>78.364092</td>\n",
       "      <td>79.007238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>49.712482</td>\n",
       "      <td>27.802960</td>\n",
       "      <td>46.379182</td>\n",
       "      <td>46.381833</td>\n",
       "      <td>84.609491</td>\n",
       "      <td>83.365786</td>\n",
       "      <td>83.918148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qg/google/umt5-base_en_US</td>\n",
       "      <td>48.035762</td>\n",
       "      <td>26.163355</td>\n",
       "      <td>44.866181</td>\n",
       "      <td>44.863262</td>\n",
       "      <td>84.208149</td>\n",
       "      <td>82.750547</td>\n",
       "      <td>83.404893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_en/checkpoint-64000</td>\n",
       "      <td>49.954044</td>\n",
       "      <td>28.132323</td>\n",
       "      <td>46.689003</td>\n",
       "      <td>46.679203</td>\n",
       "      <td>84.717369</td>\n",
       "      <td>83.349091</td>\n",
       "      <td>83.961731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>48.630212</td>\n",
       "      <td>26.812704</td>\n",
       "      <td>45.383956</td>\n",
       "      <td>45.384666</td>\n",
       "      <td>84.275341</td>\n",
       "      <td>82.973546</td>\n",
       "      <td>83.551329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en_US</td>\n",
       "      <td>original</td>\n",
       "      <td>49.879398</td>\n",
       "      <td>28.400941</td>\n",
       "      <td>46.344632</td>\n",
       "      <td>46.345589</td>\n",
       "      <td>83.903623</td>\n",
       "      <td>83.699644</td>\n",
       "      <td>83.733714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>37.176823</td>\n",
       "      <td>20.860462</td>\n",
       "      <td>35.546015</td>\n",
       "      <td>35.530793</td>\n",
       "      <td>81.805331</td>\n",
       "      <td>80.557323</td>\n",
       "      <td>81.100082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/mt5-large_pl</td>\n",
       "      <td>37.488054</td>\n",
       "      <td>21.381419</td>\n",
       "      <td>35.879115</td>\n",
       "      <td>35.832124</td>\n",
       "      <td>81.763804</td>\n",
       "      <td>80.907959</td>\n",
       "      <td>81.257814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/umt5-base_pl_PL</td>\n",
       "      <td>31.216255</td>\n",
       "      <td>16.462218</td>\n",
       "      <td>29.696829</td>\n",
       "      <td>29.683811</td>\n",
       "      <td>80.207270</td>\n",
       "      <td>78.837872</td>\n",
       "      <td>79.434323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>36.390356</td>\n",
       "      <td>20.241942</td>\n",
       "      <td>34.837703</td>\n",
       "      <td>34.847972</td>\n",
       "      <td>81.613517</td>\n",
       "      <td>80.232662</td>\n",
       "      <td>80.836636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_all/checkpoint-126000</td>\n",
       "      <td>61.212339</td>\n",
       "      <td>44.658048</td>\n",
       "      <td>58.978364</td>\n",
       "      <td>59.002348</td>\n",
       "      <td>87.115109</td>\n",
       "      <td>86.274660</td>\n",
       "      <td>86.602932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qg/google/umt5-base_sk_SK</td>\n",
       "      <td>58.259280</td>\n",
       "      <td>41.701151</td>\n",
       "      <td>56.063536</td>\n",
       "      <td>56.078700</td>\n",
       "      <td>86.328340</td>\n",
       "      <td>85.177767</td>\n",
       "      <td>85.658139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qg/google/umt5-base_all</td>\n",
       "      <td>59.350372</td>\n",
       "      <td>42.728065</td>\n",
       "      <td>57.103278</td>\n",
       "      <td>57.107775</td>\n",
       "      <td>86.670852</td>\n",
       "      <td>85.546935</td>\n",
       "      <td>86.014718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_sk/checkpoint-61000</td>\n",
       "      <td>61.715352</td>\n",
       "      <td>45.226946</td>\n",
       "      <td>59.454205</td>\n",
       "      <td>59.460529</td>\n",
       "      <td>87.167358</td>\n",
       "      <td>86.581385</td>\n",
       "      <td>86.782449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang                                   model     rouge1     rouge2  \\\n",
       "0   cs_CZ                  qg/google/mt5-large_cs  37.288131  19.425672   \n",
       "12  cs_CZ                 qg/google/umt5-base_all  35.302872  17.738190   \n",
       "16  cs_CZ                                original   9.841955   2.848823   \n",
       "4   cs_CZ  google/mt5-large_all/checkpoint-126000  37.088151  19.183201   \n",
       "8   cs_CZ               qg/google/umt5-base_cs_CZ  33.828129  16.569281   \n",
       "5   en_US  google/mt5-large_all/checkpoint-126000  49.712482  27.802960   \n",
       "9   en_US               qg/google/umt5-base_en_US  48.035762  26.163355   \n",
       "1   en_US    google/mt5-large_en/checkpoint-64000  49.954044  28.132323   \n",
       "13  en_US                 qg/google/umt5-base_all  48.630212  26.812704   \n",
       "17  en_US                                original  49.879398  28.400941   \n",
       "6   pl_PL  google/mt5-large_all/checkpoint-126000  37.176823  20.860462   \n",
       "2   pl_PL                  qg/google/mt5-large_pl  37.488054  21.381419   \n",
       "10  pl_PL               qg/google/umt5-base_pl_PL  31.216255  16.462218   \n",
       "14  pl_PL                 qg/google/umt5-base_all  36.390356  20.241942   \n",
       "7   sk_SK  google/mt5-large_all/checkpoint-126000  61.212339  44.658048   \n",
       "11  sk_SK               qg/google/umt5-base_sk_SK  58.259280  41.701151   \n",
       "15  sk_SK                 qg/google/umt5-base_all  59.350372  42.728065   \n",
       "3   sk_SK    google/mt5-large_sk/checkpoint-61000  61.715352  45.226946   \n",
       "\n",
       "       rougeL  rougeLsum  bert_score_P  bert_score_R  bert_score_F1  \n",
       "0   34.744723  34.733320     80.542296     79.557836      79.971039  \n",
       "12  32.914260  32.920015     80.186731     78.828305      79.422516  \n",
       "16   9.185948   9.185807     69.304228     67.218244      68.188828  \n",
       "4   34.605186  34.601553     80.723560     79.360574      79.957223  \n",
       "8   31.540587  31.549525     79.821813     78.364092      79.007238  \n",
       "5   46.379182  46.381833     84.609491     83.365786      83.918148  \n",
       "9   44.866181  44.863262     84.208149     82.750547      83.404893  \n",
       "1   46.689003  46.679203     84.717369     83.349091      83.961731  \n",
       "13  45.383956  45.384666     84.275341     82.973546      83.551329  \n",
       "17  46.344632  46.345589     83.903623     83.699644      83.733714  \n",
       "6   35.546015  35.530793     81.805331     80.557323      81.100082  \n",
       "2   35.879115  35.832124     81.763804     80.907959      81.257814  \n",
       "10  29.696829  29.683811     80.207270     78.837872      79.434323  \n",
       "14  34.837703  34.847972     81.613517     80.232662      80.836636  \n",
       "7   58.978364  59.002348     87.115109     86.274660      86.602932  \n",
       "11  56.063536  56.078700     86.328340     85.177767      85.658139  \n",
       "15  57.103278  57.107775     86.670852     85.546935      86.014718  \n",
       "3   59.454205  59.460529     87.167358     86.581385      86.782449  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_qg(result_jsonls):\n",
    "    data = []\n",
    "    for rjsonl in result_jsonls:\n",
    "        data += read_jsonl(rjsonl)\n",
    "    # for d in data:\n",
    "    #     if \"bert_score_R1\" in d[\"eval\"]:\n",
    "    #         t = d[\"eval\"][\"bert_score_R1\"]\n",
    "    #         d[\"eval\"][\"bert_score_R\"] = t\n",
    "    #         del d[\"eval\"][\"bert_score_R1\"]\n",
    "    # write_jsonl(result_jsonls[0], data)\n",
    "    # return\n",
    "    df = pd.DataFrame(data)\n",
    "    models = ['/'.join(m.split(\"/\")[-3:]) for m in df.model]\n",
    "    df[\"model\"] = models\n",
    "    df[\"rouge1\"] = [100*e[\"rouge1\"] for e in df[\"eval\"]]\n",
    "    df[\"rouge2\"] = [100*e[\"rouge2\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeL\"] = [100*e[\"rougeL\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeLsum\"] = [100*e[\"rougeLsum\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_P\"] = [100*e[\"bert_score_P\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_R\"] = [100*e[\"bert_score_R\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_F1\"] = [100*e[\"bert_score_F1\"] for e in df[\"eval\"]]\n",
    "    df = df[[\"lang\", \"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\", \"bert_score_P\", \"bert_score_R\", \"bert_score_F1\"]]\n",
    "    df.sort_values(\"lang\", inplace=True)\n",
    "    return df\n",
    "\n",
    "df = compare_results_qg([\n",
    "    \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\"\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " lang &                                  model &  rouge1 &  rouge2 &  rougeL &  bert\\_score\\_F1 \\\\\n",
      "\\midrule\n",
      "cs\\_CZ &                 qg/google/mt5-large\\_cs &    37.3 &    19.4 &    34.7 &           80.0 \\\\\n",
      "cs\\_CZ &                               original &     9.8 &     2.8 &     9.2 &           68.2 \\\\\n",
      "cs\\_CZ & google/mt5-large\\_all/checkpoint-126000 &    37.1 &    19.2 &    34.6 &           80.0 \\\\\n",
      "en\\_US & google/mt5-large\\_all/checkpoint-126000 &    49.7 &    27.8 &    46.4 &           83.9 \\\\\n",
      "en\\_US &   google/mt5-large\\_en/checkpoint-64000 &    50.0 &    28.1 &    46.7 &           84.0 \\\\\n",
      "en\\_US &                               original &    49.9 &    28.4 &    46.3 &           83.7 \\\\\n",
      "pl\\_PL & google/mt5-large\\_all/checkpoint-126000 &    37.2 &    20.9 &    35.5 &           81.1 \\\\\n",
      "pl\\_PL &                 qg/google/mt5-large\\_pl &    37.5 &    21.4 &    35.9 &           81.3 \\\\\n",
      "sk\\_SK & google/mt5-large\\_all/checkpoint-126000 &    61.2 &    44.7 &    59.0 &           86.6 \\\\\n",
      "sk\\_SK &   google/mt5-large\\_sk/checkpoint-61000 &    61.7 &    45.2 &    59.5 &           86.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2005688/2262563657.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))\n"
     ]
    }
   ],
   "source": [
    "print(df[~df.model.str.contains(\"umt5\")][['lang', 'model', 'rouge1', 'rouge2', 'rougeL', 'bert_score_F1']].to_latex(float_format=\"%.1f\", index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS\n",
    "`qg/ctu-aic/flan-t5-large_cs_CZ/bkp/checkpoint-12672`\n",
    "\n",
    "*{'rouge1': 0.12963591761229037, 'rouge2': 0.023885136378797505, 'rougeL': 0.12183362628568076, 'rougeLsum': 0.1217667170120719}*\n",
    "\n",
    "Wrong tokenization.\n",
    "\n",
    "`qg/google/mt5-large_cs_CZ/checkpoint-59000`\n",
    "\n",
    "*{'rouge1': 0.3694537189887302, 'rouge2': 0.19169694531279952, 'rougeL': 0.34545989041700687, 'rougeLsum': 0.34555287654344513}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ/bkp/checkpoint-6400`\n",
    "\n",
    "*{'rouge1': 0.30904739385202495, 'rouge2': 0.14175598892317176, 'rougeL': 0.2874681246496394, 'rougeLsum': 0.28755029622694217}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ`\n",
    "\n",
    "*{'rouge1': 0.3379285112695145, 'rouge2': 0.16586064794677036, 'rougeL': 0.3152727384483949, 'rougeLsum': 0.3154454957579359}*\n",
    "\n",
    "### EN\n",
    "\n",
    "`original`\n",
    "\n",
    "*{'rouge1': 0.4989229792773411, 'rouge2': 0.28414967309411343, 'rougeL': 0.4635031675966017, 'rougeLsum': 0.4634836172778146}*\n",
    "\n",
    "`qg/google/mt5-large_en/checkpoint-64000`\n",
    "\n",
    "**{'rouge1': 0.4995418652865221, 'rouge2': 0.2815535664262393, 'rougeL': 0.4668170545426994, 'rougeLsum': 0.46687703737445807}**\n",
    "\n",
    "`qg/google/flan-t5-large_en_US/checkpoint-7936`\n",
    "\n",
    "*{'rouge1': 0.5050762371759718, 'rouge2': 0.28730345133694524, 'rougeL': 0.4710796839809428, 'rougeLsum': 0.47103764958291705}*\n",
    "\n",
    "`qg/google/umt5-base_en_US`\n",
    "\n",
    "*{'rouge1': 0.48045112431026354, 'rouge2': 0.26173784145711765, 'rougeL': 0.4487262083667449, 'rougeLsum': 0.4487590621176192}*\n",
    "\n",
    "### PL\n",
    "\n",
    "`qg/google/mt5-large_pl/checkpoint-34000`\n",
    "\n",
    "*{'rouge1': 0.3670461463062099, 'rouge2': 0.20664767638201073, 'rougeL': 0.3513302909076887, 'rougeLsum': 0.3514851628255672}*\n",
    "\n",
    "`qg/google/flan-t5-large_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.2651964323903675, 'rouge2': 0.10999222537607427, 'rougeL': 0.25368293682015525, 'rougeLsum': 0.2532975070425204}*\n",
    "\n",
    "`qg/google/umt5-base_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.31209527473925364, 'rouge2': 0.16440549183090475, 'rougeL': 0.29680613676413997, 'rougeLsum': 0.29705324007033296}*\n",
    "\n",
    "### SK\n",
    "`qg/google/mt5-large_sk_SK/checkpoint-37000`\n",
    "\n",
    "*{'rouge1': 0.2947516032244862, 'rouge2': 0.13924328095469365, 'rougeL': 0.2711889534899373, 'rougeLsum': 0.2710563599995189}*\n",
    "\n",
    "`qg/google/umt5-base_sk_SK`\n",
    "*{'rouge1': 0.5825675978707048, 'rouge2': 0.41734228678000224, 'rougeL': 0.5607684287432402, 'rougeLsum': 0.560618385882808}*\n",
    "\n",
    "### ALL\n",
    "\n",
    "`qg/google/umt5-base_all`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4572821393722631, 'rouge2': 0.2663545003075309, 'rougeL': 0.43077904314996096, 'rougeLsum': 0.43072475188146}*\n",
    "\n",
    "**CS** *{'rouge1': 0.35290062436342096, 'rouge2': 0.17738150128215946, 'rougeL': 0.3292826941280448, 'rougeLsum': 0.3290628070321041}*\n",
    "\n",
    "**EN** *{'rouge1': 0.48636008671818154,'rouge2': 0.2681378422877396, 'rougeL': 0.4539385644052849, 'rougeLsum': 0.4539682258809208}*\n",
    "\n",
    "**PL** *{'rouge1': 0.36408309004184375, 'rouge2': 0.20234412375822144, 'rougeL': 0.3484808037947017, 'rougeLsum': 0.3484233231283168}*\n",
    "\n",
    "**SK** *{'rouge1': 0.5935977294706721, 'rouge2': 0.4272281779017747, 'rougeL': 0.5711202748270763, 'rougeLsum': 0.5709580363216058}*\n",
    "\n",
    "`qg/google/mt5-large_all/BKP/checkpoint-126000`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4712879903083035, 'rouge2': 0.2790771005345815,  'rougeL': 0.44412574432094815,  'rougeLsum': 0.4440181809982411}*\n",
    "\n",
    "**CS** **{'rouge1': 0.37076781953491367, 'rouge2': 0.19188317187558196, 'rougeL': 0.34603606602711284, 'rougeLsum': 0.3458732199471718}**\n",
    "\n",
    "**EN** *{'rouge1': 0.4972121341475896, 'rouge2': 0.27814731357909395, 'rougeL': 0.46391560371478174, 'rougeLsum': 0.46394229428970657}*\n",
    "\n",
    "**PL** **{'rouge1': 0.3717109027777702, 'rouge2': 0.20806629045849118, 'rougeL': 0.35534417379213407, 'rougeLsum': 0.35545025872361985}**\n",
    "\n",
    "**SK** **{'rouge1': 0.6120836094748034, 'rouge2': 0.4468872126953193, 'rougeL': 0.5898635208080331, 'rougeLsum': 0.5898424756234816}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for model inference\n",
    "see `scripts/wiki_qg.py` for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CZ\n",
    "lang = \"cs_CZ\"\n",
    "# model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-32000\")\n",
    "\n",
    "# SK\n",
    "lang = \"sk_SK\"\n",
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk_SK/checkpoint-37000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS\n",
    "# data = read_jsonl(\"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\")\n",
    "\n",
    "# SK\n",
    "data = read_jsonl(\"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Vysoký grúň (Laborecká vrchovina)',\n",
       " 'context': 'Cez vrch Vysoký grúň vedie hlavná  červená turistická značka, ktorá zároveň vedie po hlavnom karpatskom hrebeni cez najvýchodnejší bod Slovenska – trojmedzie (1207.7 Mnm) na vrchu Kremenec (1221.0 Mnm) a prechádza po slovensko-poľskej štátnej hranici cez viacero vrchov s viacerými panoramatickými vyhliadkami, ako napr. Kamenná lúka (1200.9 Mnm), Jarabá skala (1199.0 Mnm), Ďurkovec (1188.7 Mnm), Pľaša (1162.8 Mnm), ďalej cez Ruské sedlo (801.0 Mnm), vrchy Rypy (1002.7 Mnm), Strop, (1011.2 Mnm), Černiny (929.4 Mnm), Laborecký priesmyk (684.0 Mnm) až k Duklianskemu priesmyku (502.0 Mnm).',\n",
       " 'question': 'Akú nadmorskú výšku má vrch Kremenec?',\n",
       " 'answer': '1221.0 Mnm'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy\n",
      "Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura\n",
      "Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky\n",
      "v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo\n",
      "působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform\n",
      "mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově\n",
      "Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby\n",
      "Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s\n",
      "vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o\n",
      "pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s\n",
      "ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli\n",
      "kvůli vzdušnému poplachu v pátek na čas do hotelového krytu.\n",
      "Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a\n",
      "Slovenska poznamenala, že vysoce postavení zahraniční představitelé od\n",
      "začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\n",
      "NATO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['V ktorom štáte pôsobil prezident Pavlo Pavlov na vrcholnej pozicii?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[120]\n",
    "answer = sample[\"answer\"]\n",
    "context = \"Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli kvůli vzdušnému poplachu v pátek na čas do hotelového krytu. Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a Slovenska poznamenala, že vysoce postavení zahraniční představitelé od začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\"\n",
    "answer = \"NATO\"\n",
    "print(textwrap.fill(context))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32150, 1024)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "model_id = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "accents = \"áčďéěíňóřšťúůýž\" # CS\n",
    "accents += \"ąćęłńóśźż\" # PL\n",
    "accents += \"áäčďéíĺľňóôŕšťúýž\" # SK\n",
    "accents += accents.upper()\n",
    "accents = set(c for c in accents)\n",
    "new_tokens = accents - set(tokenizer.vocab.keys())\n",
    "\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53385a98a1e4eca9a5d2b8095d29e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008115768432617188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 3001279361,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806913f99a494f26bff1d0cd07d95828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016201257705688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b8ff0c1954808beb0a414dd7cda53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/44e85df0c017c2ee04a322a13ddd14d0674f357d', commit_message='Upload model', commit_description='', oid='44e85df0c017c2ee04a322a13ddd14d0674f357d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008070945739746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4969ea29d072489eb0b6448a8201b0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00809168815612793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "spiece.model",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dbb221150a46b1be926a0aef862f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/6e995ffb333de1a0238236976bc7a9271ddf1e3a', commit_message='Upload tokenizer', commit_description='', oid='6e995ffb333de1a0238236976bc7a9271ddf1e3a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nechť již hříš né saxofony ď áblů rozezvučí síň ú dě sný mi tóny waltzu, tanga a quickstepu.</s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Nechť již hříšné saxofony ďáblů rozezvučí síň úděsnými tóny waltzu, tanga a quickstepu.\"\n",
    "ids = tokenizer(txt)[\"input_ids\"]\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1484,\n",
       " 524,\n",
       " 2,\n",
       " 3,\n",
       " 354,\n",
       " 23,\n",
       " 2,\n",
       " 3,\n",
       " 107,\n",
       " 2,\n",
       " 29,\n",
       " 154,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 226,\n",
       " 858,\n",
       " 106,\n",
       " 63,\n",
       " 3,\n",
       " 2,\n",
       " 2975,\n",
       " 115,\n",
       " 40,\n",
       " 2,\n",
       " 3,\n",
       " 9860,\n",
       " 457,\n",
       " 208,\n",
       " 76,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 2,\n",
       " 7,\n",
       " 29,\n",
       " 2,\n",
       " 51,\n",
       " 23,\n",
       " 3,\n",
       " 17,\n",
       " 15742,\n",
       " 63,\n",
       " 3,\n",
       " 5380,\n",
       " 17,\n",
       " 1000,\n",
       " 6,\n",
       " 3,\n",
       " 8967,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 1704,\n",
       " 7910,\n",
       " 76,\n",
       " 5,\n",
       " 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Á',\n",
       " 'Ä',\n",
       " 'Í',\n",
       " 'Ó',\n",
       " 'Ô',\n",
       " 'Ú',\n",
       " 'Ý',\n",
       " 'í',\n",
       " 'ú',\n",
       " 'ý',\n",
       " 'Ą',\n",
       " 'ą',\n",
       " 'Ć',\n",
       " 'ć',\n",
       " 'Č',\n",
       " 'č',\n",
       " 'Ď',\n",
       " 'ď',\n",
       " 'Ę',\n",
       " 'ę',\n",
       " 'Ě',\n",
       " 'ě',\n",
       " 'Ĺ',\n",
       " 'ĺ',\n",
       " 'Ľ',\n",
       " 'ľ',\n",
       " 'Ł',\n",
       " 'ł',\n",
       " 'Ń',\n",
       " 'ń',\n",
       " 'Ň',\n",
       " 'ň',\n",
       " 'Ŕ',\n",
       " 'ŕ',\n",
       " 'Ř',\n",
       " 'ř',\n",
       " 'Ś',\n",
       " 'ś',\n",
       " 'Š',\n",
       " 'š',\n",
       " 'Ť',\n",
       " 'ť',\n",
       " 'Ů',\n",
       " 'ů',\n",
       " 'Ź',\n",
       " 'ź',\n",
       " 'Ż',\n",
       " 'ż',\n",
       " 'Ž',\n",
       " 'ž'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32100, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflarge",
   "language": "python",
   "name": "hflarge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

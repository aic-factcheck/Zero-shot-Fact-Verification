{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import Dict, List, Set, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import bert_score\n",
    "\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.batch import batch_apply\n",
    "from aic_nlp_utils.encoding import nfc\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "# from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "# import stanza\n",
    "# stanza.download(\"en\")\n",
    "\n",
    "# sys.path.append('Claim_Generation')\n",
    "# from T5_QG import pipeline\n",
    "# from distractor_generation import Distractor_Generation\n",
    "\n",
    "%cd /home/drchajan/devel/python/FC/Zero-shot-Fact-Verification\n",
    "\n",
    "from zshot_fact_verify.models.arguments import ModelArguments, DataTrainingArguments\n",
    "from zshot_fact_verify.models.load import load_tokenizer_and_model, find_last_checkpoint\n",
    "from zshot_fact_verify.qg.question_generation import BatchQuestionGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares data to train QG models for different languages.\n",
    "The paper used T5 model from here: https://github.com/patil-suraj/question_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least sk-quad dataset has word-tokenized question, this should remove all unneeded whitespace\n",
    "def word_detokenize(txt: str) -> str:\n",
    "    def pair_detokenize(txt, s):\n",
    "        sub = \" \" + s + \" \"\n",
    "        idxs = [m.start() for m in re.finditer(sub, txt)]\n",
    "        if len(idxs) > 0 and len(idxs) % 2 == 0:\n",
    "            # ignore odd number of pair substrings\n",
    "            otxt = \"\"\n",
    "            first = 0\n",
    "            for i, idx in enumerate(idxs):\n",
    "                if i % 2 == 0:\n",
    "                    otxt += txt[first:idx] + ' ' + s\n",
    "                else:\n",
    "                    otxt += txt[first:idx] + s + ' '\n",
    "                first = idx + 3\n",
    "            otxt += txt[first:]\n",
    "            return otxt\n",
    "        else:\n",
    "            return txt\n",
    "    \n",
    "    txt = txt.replace(\"``\", '\"').replace(\"''\", '\"').replace(\",,\", '\"')\n",
    "    txt = pair_detokenize(txt, '\"')\n",
    "    txt = txt.replace(\" '\", \"'\")\n",
    "    txt = txt.replace(\" - \", \"-\")\n",
    "    txt = txt.replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" ?\", \"?\").replace(\" :\", \":\").replace(\" ;\", \";\")\n",
    "    txt = txt.replace(\"( \", \"(\").replace(\" )\", \")\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_squad(fsrc, fdst, word_detokenize_questions=False):\n",
    "    # converts SQUAD format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers if Squad 2.0 is given\n",
    "    data = read_json(fsrc)[\"data\"]\n",
    "    records = []\n",
    "    for rec in tqdm(data):\n",
    "        title = nfc(rec[\"title\"])\n",
    "        for par in rec[\"paragraphs\"]:\n",
    "            context = nfc(par[\"context\"])\n",
    "            for qas in par[\"qas\"]:\n",
    "                if \"is_impossible\" in qas and qas[\"is_impossible\"]:\n",
    "                    continue\n",
    "                answer_set = set()\n",
    "                for ans in qas[\"answers\"]:\n",
    "                    ans = ans[\"text\"]\n",
    "                    if ans[-1] in [\".\", \",\"]:\n",
    "                        ans = ans[:-1]\n",
    "                    answer_set.add(ans)\n",
    "                answers = sorted(list(answer_set))\n",
    "                for answer in answers:\n",
    "                    question = qas[\"question\"].strip()\n",
    "                    question = question[0].upper() + question[1:]\n",
    "                    question = question.replace(\"  \", \" \")\n",
    "                    if word_detokenize_questions:\n",
    "                        question = word_detokenize(question)\n",
    "                    if not (question.endswith(\"?\") or question.endswith('?\"')):\n",
    "                        if not question.lower().startswith(\"name\"):\n",
    "                            if question[-1] in [\".\", \":\", \">\", \"/\"]: # Probably wrong parsing of original data\n",
    "                                question = question[:-1] + \"?\"\n",
    "                            else:\n",
    "                                question += \"?\"\n",
    "                    question = nfc(question)\n",
    "                    answer = nfc(answer)\n",
    "                    print(question)\n",
    "                    records.append({\"title\": title, \"context\": context, \"question\": question, \"answer\": answer})\n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "WORD_DETOKENIZE = False\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-cs', \"train-v1.1.json\", \"dev-v1.1.json\"\n",
    "# SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-sk', \"train-230321.json\", \"dev-230321.json\"\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV, WORD_DETOKENIZE = 'sk-quad-220614', \"sk-quad-220614-train.json\", \"sk-quad-220614-dev.json\", True\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_DEV), Path(QG_ROOT, SQUAD_DEV), word_detokenize_questions=WORD_DETOKENIZE)\n",
    "convert_and_fix_squad(Path(SQUAD_ROOT, SQUAD_TRN), Path(QG_ROOT, SQUAD_TRN), word_detokenize_questions=WORD_DETOKENIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_fix_csv_squad(fsrc, fdst):\n",
    "    # converts CSV SQUAD (e.g. SQUAD-pl) format to \"linear\" JSONL usable for training seq2seq model\n",
    "    # skips impossible answers\n",
    "    # title is missing in SQUAD-PL\n",
    "    df = pd.read_csv(fsrc)[[\"context\", \"question\", \"answer_text\"]]\n",
    "    print(f\"#records = {df.shape}\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(f\"after drop #records = {df.shape}\")\n",
    "\n",
    "    records = []\n",
    "    for idx, r in tqdm(df.iterrows()):\n",
    "        title = None\n",
    "        context = nfc(str(r.context))\n",
    "        question = nfc(str(r.question))\n",
    "        answer = nfc(str(r.answer_text))\n",
    "        print(question)\n",
    "        # print(\" > \" + answer)\n",
    "        rec = {\"title\": title, \"context\": context, \"question\": question, \"answer\": answer}\n",
    "        records.append(rec)\n",
    "  \n",
    "    write_jsonl(fdst, records, mkdir=True)\n",
    "\n",
    "\n",
    "SQUAD_DIR, SQUAD_TRN, SQUAD_DEV = 'squad-pl', \"train\", \"test\"\n",
    "SQUAD_ROOT = Path(f\"/mnt/data/factcheck/squad/{SQUAD_DIR}\")\n",
    "QG_ROOT = Path(f\"/mnt/data/factcheck/qg/{SQUAD_DIR}\")\n",
    "\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_DEV}.csv\"), Path(QG_ROOT, f\"{SQUAD_DEV}.jsonl\"))\n",
    "convert_and_fix_csv_squad(Path(SQUAD_ROOT, f\"{SQUAD_TRN}.csv\"), Path(QG_ROOT, f\"{SQUAD_TRN}.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SQUAD Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 252281 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\n",
      "writing 40933 records to /mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\n"
     ]
    }
   ],
   "source": [
    "def combine_squads(split_files, out_file, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for sfile in split_files:\n",
    "        assert len(sfile.items()) == 1\n",
    "        for lang, path_ in sfile.items():\n",
    "            pass\n",
    "        split = read_jsonl(path_)\n",
    "        for s in split:\n",
    "            s[\"lang\"] = lang\n",
    "        data += split\n",
    "    rng.shuffle(data)\n",
    "    print(f\"writing {len(data)} records to {out_file}\")\n",
    "    write_jsonl(out_file, data, mkdir=True)\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/train-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/train-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/train.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-train.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/train.jsonl\")\n",
    "\n",
    "combine_squads([\n",
    "    {\"cs\": \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"},\n",
    "    {\"en\": \"/mnt/data/factcheck/qg/squad-en/dev-v1.1.jsonl\"},\n",
    "    {\"pl\": \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"},\n",
    "    {\"sk\": \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"}], \n",
    "    \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation by ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=True, device=\"cuda\"):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = model_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = model_inputs[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "def predict_original_paper(data):\n",
    "    from zshot_fact_verify.claim_generation.T5_QG import pipeline\n",
    "    qg_nlp = pipeline(\"question-generation\", model='valhalla/t5-base-qg-hl', qg_format=\"highlight\", gpu_index=0)\n",
    "    \n",
    "    def predict_batch(data): \n",
    "        sources = [s[\"context\"] for s in data]\n",
    "        answers = [s[\"answer\"] for s in data]\n",
    "        Y = qg_nlp.batch_qg_with_answer(sources, answers)\n",
    "        return Y\n",
    "    \n",
    "    Y = batch_apply(predict_batch, data, batch_size=32, show_progress=True)\n",
    "    Y = [y[\"question\"] for y in Y]\n",
    "    T = [s[\"question\"] for s in data]\n",
    "    return Y, T\n",
    "\n",
    "def predict_split(model, tokenizer, data, batch_size=128):\n",
    "    # use batches for faster\n",
    "    T = []\n",
    "    Y = []\n",
    "    X = [nfc(sample[\"answer\"] + \"</s>\" + sample[\"context\"]) for sample in data]\n",
    "    pfunc = lambda batch: predict(model, tokenizer, batch)\n",
    "    Y = batch_apply(pfunc, X, batch_size=batch_size, show_progress=True)\n",
    "    T = [nfc(sample[\"question\"]) for sample in data]\n",
    "    return Y, T\n",
    "\n",
    "def evaluate_rouge(Y, T):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(predictions=Y, references=T)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_quality(cfgs, out_json):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = []\n",
    "    for cfg in cfgs:\n",
    "        lang = cfg['lang']\n",
    "        data_file = cfg[\"data_file\"]\n",
    "        model_name = cfg[\"model\"]\n",
    "\n",
    "        if model_name == \"original\":\n",
    "            Y, T = predict_split(predict_original_paper)\n",
    "        else:\n",
    "            model_short = \"/\".join(Path(model_name).parts[8:])\n",
    "            print(f\"lang: {lang}, model: {model_short}, data file: {data_file}\")\n",
    "\n",
    "            data = read_jsonl(data_file)\n",
    "            print(f\"  loaded {len(data)} samples\")\n",
    "            \n",
    "            model_args = ModelArguments(model_name_or_path=model_name)\n",
    "            tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n",
    "            model.to(\"cuda\")\n",
    "            model.eval();\n",
    "\n",
    "            Y, T = predict_split(model, tokenizer, data, batch_size=32)\n",
    "\n",
    "        ev = rouge.compute(predictions=Y, references=T)\n",
    "\n",
    "        bsP, bsR, bsF1 = bert_score.score(Y, T, model_type=\"bert-base-multilingual-cased\")\n",
    "        ev[\"bert_score_P\"] = bsP.mean().item()\n",
    "        ev[\"bert_score_R\"] = bsR.mean().item()\n",
    "        ev[\"bert_score_F1\"] = bsF1.mean().item()\n",
    "        \n",
    "        print(f\"  EVAL = {ev}\")\n",
    "        res = cfg.copy()\n",
    "        res[\"eval\"] = ev\n",
    "        res[\"Y\"] = Y\n",
    "        res[\"T\"] = T\n",
    "        results.append(res)\n",
    "        write_jsonl(out_json, [res], append=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = \"all\"\n",
    "LANG_SHORT = \"all\"\n",
    "# NOT FULLY TRAINED!\n",
    "# MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_all/BKP/checkpoint-23552\"\n",
    "# MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/umt5-base_all\"\n",
    "# NOT FULLY TRAINED!\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_all/BKP/checkpoint-126000\"\n",
    "MODEL_NAME_CS = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_cs\" # FINAL \n",
    "MODEL_NAME_EN = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_en/checkpoint-64000\" # FINAL\n",
    "MODEL_NAME_PL = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_pl\" # CHECK!\n",
    "MODEL_NAME_SK = \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk/checkpoint-61000\" # CHECK\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK},\n",
    "    \n",
    "    {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL},\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: cs_CZ, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\n",
      "  loaded 11722 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008263349533081055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 367,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3943c4b61972459ca42fd7cfe16c2513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.09673669139281843, 'rouge2': 0.03196764873500374, 'rougeL': 0.07624961780557481, 'rougeLsum': 0.07621639981096323, 'bert_score_P': 0.5656077265739441, 'bert_score_R1': 0.6789258718490601, 'bert_score_F1': 0.6156735420227051}\n",
      "lang: en_US, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\n",
      "  loaded 17598 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008116960525512695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 550,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642036f8ab6431ab4b2373683eecb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.1320159537637445, 'rouge2': 0.045013610505329746, 'rougeL': 0.10644395425593958, 'rougeLsum': 0.1064558074862242, 'bert_score_P': 0.5972579121589661, 'bert_score_R1': 0.6972867250442505, 'bert_score_F1': 0.6421326398849487}\n",
      "lang: pl_PL, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qg/squad-pl/test.jsonl\n",
      "  loaded 3805 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008367776870727539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 119,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af37a03ae0c42788ee95e2981a79b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EVAL = {'rouge1': 0.09165418126936631, 'rouge2': 0.03311040580656982, 'rougeL': 0.07488752399469388, 'rougeLsum': 0.07494255462640638, 'bert_score_P': 0.5692041516304016, 'bert_score_R1': 0.6860596537590027, 'bert_score_F1': 0.6206879615783691}\n",
      "lang: sk_SK, model: experiments/qa2d/google/umt5-base_all, data file: /mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\n",
      "  loaded 7808 samples\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00798487663269043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 244,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c15306d62a4b928e47b9027613e8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LANG = \"all\"\n",
    "LANG_SHORT = \"all\"\n",
    "MODEL_NAME_ALL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_all\"\n",
    "MODEL_NAME_CS = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_cs_CZ\" # FINAL \n",
    "MODEL_NAME_EN = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_en_US\" # FINAL\n",
    "MODEL_NAME_PL = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_pl_PL\" # FINAL\n",
    "MODEL_NAME_SK = \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qa2d/google/umt5-base_sk_SK\" # FINAL\n",
    "\n",
    "HIGHLIGHT = False\n",
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    # {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_CS, \"data_file\": DEV_FILE_CS},\n",
    "    # {\"lang\": \"en_US\", \"model\": MODEL_NAME_EN, \"data_file\": DEV_FILE_EN},\n",
    "    # {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_PL, \"data_file\": DEV_FILE_PL},\n",
    "    # {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_SK, \"data_file\": DEV_FILE_SK}, # done\n",
    "    \n",
    "    # {\"lang\": \"all\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_ALL}, # missing!\n",
    "    {\"lang\": \"cs_CZ\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_EN},\n",
    "    {\"lang\": \"pl_PL\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_PL},\n",
    "    {\"lang\": \"sk_SK\", \"model\": MODEL_NAME_ALL, \"data_file\": DEV_FILE_SK},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_FILE_ALL = \"/mnt/data/factcheck/qg/squad-cs_en_pl_sk/dev.jsonl\" #ALL\n",
    "DEV_FILE_CS = \"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\"\n",
    "DEV_FILE_EN = \"/mnt/data/factcheck/qg/squad-en//dev-v1.1.jsonl\"\n",
    "DEV_FILE_PL = \"/mnt/data/factcheck/qg/squad-pl/test.jsonl\"\n",
    "DEV_FILE_SK = \"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\"\n",
    "\n",
    "\n",
    "cfgs = [\n",
    "    {\"lang\": \"cs_CZ\", \"model\": \"original\", \"data_file\": DEV_FILE_CS},\n",
    "    {\"lang\": \"en_US\", \"model\": \"original\", \"data_file\": DEV_FILE_EN},\n",
    "]\n",
    "\n",
    "results = evaluate_quality(cfgs, \"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bert_score_P</th>\n",
       "      <th>bert_score_R</th>\n",
       "      <th>bert_score_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-126000</td>\n",
       "      <td>0.471182</td>\n",
       "      <td>0.279124</td>\n",
       "      <td>0.444101</td>\n",
       "      <td>0.444055</td>\n",
       "      <td>0.837140</td>\n",
       "      <td>0.825126</td>\n",
       "      <td>0.830340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qg/google/mt5-large_cs</td>\n",
       "      <td>0.372638</td>\n",
       "      <td>0.194475</td>\n",
       "      <td>0.347349</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.805423</td>\n",
       "      <td>0.795578</td>\n",
       "      <td>0.799710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.096737</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.076250</td>\n",
       "      <td>0.076216</td>\n",
       "      <td>0.565608</td>\n",
       "      <td>0.678926</td>\n",
       "      <td>0.615674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>qa2d/google/umt5-base_cs_CZ</td>\n",
       "      <td>0.119408</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>0.095325</td>\n",
       "      <td>0.095262</td>\n",
       "      <td>0.592455</td>\n",
       "      <td>0.679738</td>\n",
       "      <td>0.631591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs_CZ</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-126000</td>\n",
       "      <td>0.370568</td>\n",
       "      <td>0.191944</td>\n",
       "      <td>0.345985</td>\n",
       "      <td>0.345969</td>\n",
       "      <td>0.807236</td>\n",
       "      <td>0.793606</td>\n",
       "      <td>0.799572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en_US</td>\n",
       "      <td>google/mt5-large_en/checkpoint-64000</td>\n",
       "      <td>0.499655</td>\n",
       "      <td>0.281486</td>\n",
       "      <td>0.466864</td>\n",
       "      <td>0.466891</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.833491</td>\n",
       "      <td>0.839617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.132016</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.106444</td>\n",
       "      <td>0.106456</td>\n",
       "      <td>0.597258</td>\n",
       "      <td>0.697287</td>\n",
       "      <td>0.642133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en_US</td>\n",
       "      <td>qa2d/google/umt5-base_en_US</td>\n",
       "      <td>0.173218</td>\n",
       "      <td>0.055617</td>\n",
       "      <td>0.140831</td>\n",
       "      <td>0.140864</td>\n",
       "      <td>0.635368</td>\n",
       "      <td>0.699554</td>\n",
       "      <td>0.664682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en_US</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-126000</td>\n",
       "      <td>0.497176</td>\n",
       "      <td>0.278051</td>\n",
       "      <td>0.463771</td>\n",
       "      <td>0.463899</td>\n",
       "      <td>0.846095</td>\n",
       "      <td>0.833658</td>\n",
       "      <td>0.839181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qg/google/mt5-large_pl</td>\n",
       "      <td>0.374747</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>0.358474</td>\n",
       "      <td>0.358444</td>\n",
       "      <td>0.817638</td>\n",
       "      <td>0.809080</td>\n",
       "      <td>0.812578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qa2d/google/umt5-base_all</td>\n",
       "      <td>0.091654</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.074888</td>\n",
       "      <td>0.074943</td>\n",
       "      <td>0.569204</td>\n",
       "      <td>0.686060</td>\n",
       "      <td>0.620688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>qa2d/google/umt5-base_pl_PL</td>\n",
       "      <td>0.117411</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.096403</td>\n",
       "      <td>0.096316</td>\n",
       "      <td>0.604542</td>\n",
       "      <td>0.687758</td>\n",
       "      <td>0.642136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pl_PL</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-126000</td>\n",
       "      <td>0.371695</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.355327</td>\n",
       "      <td>0.355342</td>\n",
       "      <td>0.818053</td>\n",
       "      <td>0.805573</td>\n",
       "      <td>0.811001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>google/mt5-large_sk/checkpoint-61000</td>\n",
       "      <td>0.617183</td>\n",
       "      <td>0.452607</td>\n",
       "      <td>0.594585</td>\n",
       "      <td>0.594490</td>\n",
       "      <td>0.871674</td>\n",
       "      <td>0.865814</td>\n",
       "      <td>0.867824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>qa2d/google/umt5-base_sk_SK</td>\n",
       "      <td>0.149430</td>\n",
       "      <td>0.059350</td>\n",
       "      <td>0.116441</td>\n",
       "      <td>0.116475</td>\n",
       "      <td>0.603630</td>\n",
       "      <td>0.684024</td>\n",
       "      <td>0.640171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sk_SK</td>\n",
       "      <td>mt5-large_all/BKP/checkpoint-126000</td>\n",
       "      <td>0.612067</td>\n",
       "      <td>0.446923</td>\n",
       "      <td>0.589893</td>\n",
       "      <td>0.589718</td>\n",
       "      <td>0.871151</td>\n",
       "      <td>0.862747</td>\n",
       "      <td>0.866029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang                                 model    rouge1    rouge2    rougeL  \\\n",
       "0     all   mt5-large_all/BKP/checkpoint-126000  0.471182  0.279124  0.444101   \n",
       "1   cs_CZ                qg/google/mt5-large_cs  0.372638  0.194475  0.347349   \n",
       "2   cs_CZ             qa2d/google/umt5-base_all  0.096737  0.031968  0.076250   \n",
       "3   cs_CZ           qa2d/google/umt5-base_cs_CZ  0.119408  0.038116  0.095325   \n",
       "4   cs_CZ   mt5-large_all/BKP/checkpoint-126000  0.370568  0.191944  0.345985   \n",
       "5   en_US  google/mt5-large_en/checkpoint-64000  0.499655  0.281486  0.466864   \n",
       "6   en_US             qa2d/google/umt5-base_all  0.132016  0.045014  0.106444   \n",
       "7   en_US           qa2d/google/umt5-base_en_US  0.173218  0.055617  0.140831   \n",
       "8   en_US   mt5-large_all/BKP/checkpoint-126000  0.497176  0.278051  0.463771   \n",
       "9   pl_PL                qg/google/mt5-large_pl  0.374747  0.213585  0.358474   \n",
       "10  pl_PL             qa2d/google/umt5-base_all  0.091654  0.033110  0.074888   \n",
       "11  pl_PL           qa2d/google/umt5-base_pl_PL  0.117411  0.040446  0.096403   \n",
       "12  pl_PL   mt5-large_all/BKP/checkpoint-126000  0.371695  0.208376  0.355327   \n",
       "13  sk_SK  google/mt5-large_sk/checkpoint-61000  0.617183  0.452607  0.594585   \n",
       "14  sk_SK           qa2d/google/umt5-base_sk_SK  0.149430  0.059350  0.116441   \n",
       "15  sk_SK   mt5-large_all/BKP/checkpoint-126000  0.612067  0.446923  0.589893   \n",
       "\n",
       "    rougeLsum  bert_score_P  bert_score_R  bert_score_F1  \n",
       "0    0.444055      0.837140      0.825126       0.830340  \n",
       "1    0.347151      0.805423      0.795578       0.799710  \n",
       "2    0.076216      0.565608      0.678926       0.615674  \n",
       "3    0.095262      0.592455      0.679738       0.631591  \n",
       "4    0.345969      0.807236      0.793606       0.799572  \n",
       "5    0.466891      0.847174      0.833491       0.839617  \n",
       "6    0.106456      0.597258      0.697287       0.642133  \n",
       "7    0.140864      0.635368      0.699554       0.664682  \n",
       "8    0.463899      0.846095      0.833658       0.839181  \n",
       "9    0.358444      0.817638      0.809080       0.812578  \n",
       "10   0.074943      0.569204      0.686060       0.620688  \n",
       "11   0.096316      0.604542      0.687758       0.642136  \n",
       "12   0.355342      0.818053      0.805573       0.811001  \n",
       "13   0.594490      0.871674      0.865814       0.867824  \n",
       "14   0.116475      0.603630      0.684024       0.640171  \n",
       "15   0.589718      0.871151      0.862747       0.866029  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_qg(result_jsonls):\n",
    "    data = []\n",
    "    for rjsonl in result_jsonls:\n",
    "        data += read_jsonl(rjsonl)\n",
    "    # for d in data:\n",
    "    #     if \"bert_score_R1\" in d[\"eval\"]:\n",
    "    #         t = d[\"eval\"][\"bert_score_R1\"]\n",
    "    #         d[\"eval\"][\"bert_score_R\"] = t\n",
    "    #         del d[\"eval\"][\"bert_score_R1\"]\n",
    "    # write_jsonl(result_jsonls[0], data)\n",
    "    # return\n",
    "    df = pd.DataFrame(data)\n",
    "    models = ['/'.join(m.split(\"/\")[-3:]) for m in df.model]\n",
    "    df[\"model\"] = models\n",
    "    df[\"rouge1\"] = [e[\"rouge1\"] for e in df[\"eval\"]]\n",
    "    df[\"rouge2\"] = [e[\"rouge2\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeL\"] = [e[\"rougeL\"] for e in df[\"eval\"]]\n",
    "    df[\"rougeLsum\"] = [e[\"rougeLsum\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_P\"] = [e[\"bert_score_P\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_R\"] = [e[\"bert_score_R\"] for e in df[\"eval\"]]\n",
    "    df[\"bert_score_F1\"] = [e[\"bert_score_F1\"] for e in df[\"eval\"]]\n",
    "    df = df[[\"lang\", \"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\", \"bert_score_P\", \"bert_score_R\", \"bert_score_F1\"]]\n",
    "    df.sort_values(\"lang\", inplace=True)\n",
    "    return df\n",
    "\n",
    "df = compare_results_qg([\n",
    "    \"/mnt/personal/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/results.jsonl\"\n",
    "])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS\n",
    "`qg/ctu-aic/flan-t5-large_cs_CZ/bkp/checkpoint-12672`\n",
    "\n",
    "*{'rouge1': 0.12963591761229037, 'rouge2': 0.023885136378797505, 'rougeL': 0.12183362628568076, 'rougeLsum': 0.1217667170120719}*\n",
    "\n",
    "Wrong tokenization.\n",
    "\n",
    "`qg/google/mt5-large_cs_CZ/checkpoint-59000`\n",
    "\n",
    "*{'rouge1': 0.3694537189887302, 'rouge2': 0.19169694531279952, 'rougeL': 0.34545989041700687, 'rougeLsum': 0.34555287654344513}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ/bkp/checkpoint-6400`\n",
    "\n",
    "*{'rouge1': 0.30904739385202495, 'rouge2': 0.14175598892317176, 'rougeL': 0.2874681246496394, 'rougeLsum': 0.28755029622694217}*\n",
    "\n",
    "`qg/google/umt5-base_cs_CZ`\n",
    "\n",
    "*{'rouge1': 0.3379285112695145, 'rouge2': 0.16586064794677036, 'rougeL': 0.3152727384483949, 'rougeLsum': 0.3154454957579359}*\n",
    "\n",
    "### EN\n",
    "\n",
    "`original`\n",
    "\n",
    "*{'rouge1': 0.4989229792773411, 'rouge2': 0.28414967309411343, 'rougeL': 0.4635031675966017, 'rougeLsum': 0.4634836172778146}*\n",
    "\n",
    "`qg/google/mt5-large_en/checkpoint-64000`\n",
    "\n",
    "**{'rouge1': 0.4995418652865221, 'rouge2': 0.2815535664262393, 'rougeL': 0.4668170545426994, 'rougeLsum': 0.46687703737445807}**\n",
    "\n",
    "`qg/google/flan-t5-large_en_US/checkpoint-7936`\n",
    "\n",
    "*{'rouge1': 0.5050762371759718, 'rouge2': 0.28730345133694524, 'rougeL': 0.4710796839809428, 'rougeLsum': 0.47103764958291705}*\n",
    "\n",
    "`qg/google/umt5-base_en_US`\n",
    "\n",
    "*{'rouge1': 0.48045112431026354, 'rouge2': 0.26173784145711765, 'rougeL': 0.4487262083667449, 'rougeLsum': 0.4487590621176192}*\n",
    "\n",
    "### PL\n",
    "\n",
    "`qg/google/mt5-large_pl/checkpoint-34000`\n",
    "\n",
    "*{'rouge1': 0.3670461463062099, 'rouge2': 0.20664767638201073, 'rougeL': 0.3513302909076887, 'rougeLsum': 0.3514851628255672}*\n",
    "\n",
    "`qg/google/flan-t5-large_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.2651964323903675, 'rouge2': 0.10999222537607427, 'rougeL': 0.25368293682015525, 'rougeLsum': 0.2532975070425204}*\n",
    "\n",
    "`qg/google/umt5-base_pl_PL`\n",
    "\n",
    "*{'rouge1': 0.31209527473925364, 'rouge2': 0.16440549183090475, 'rougeL': 0.29680613676413997, 'rougeLsum': 0.29705324007033296}*\n",
    "\n",
    "### SK\n",
    "`qg/google/mt5-large_sk_SK/checkpoint-37000`\n",
    "\n",
    "*{'rouge1': 0.2947516032244862, 'rouge2': 0.13924328095469365, 'rougeL': 0.2711889534899373, 'rougeLsum': 0.2710563599995189}*\n",
    "\n",
    "`qg/google/umt5-base_sk_SK`\n",
    "*{'rouge1': 0.5825675978707048, 'rouge2': 0.41734228678000224, 'rougeL': 0.5607684287432402, 'rougeLsum': 0.560618385882808}*\n",
    "\n",
    "### ALL\n",
    "\n",
    "`qg/google/umt5-base_all`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4572821393722631, 'rouge2': 0.2663545003075309, 'rougeL': 0.43077904314996096, 'rougeLsum': 0.43072475188146}*\n",
    "\n",
    "**CS** *{'rouge1': 0.35290062436342096, 'rouge2': 0.17738150128215946, 'rougeL': 0.3292826941280448, 'rougeLsum': 0.3290628070321041}*\n",
    "\n",
    "**EN** *{'rouge1': 0.48636008671818154,'rouge2': 0.2681378422877396, 'rougeL': 0.4539385644052849, 'rougeLsum': 0.4539682258809208}*\n",
    "\n",
    "**PL** *{'rouge1': 0.36408309004184375, 'rouge2': 0.20234412375822144, 'rougeL': 0.3484808037947017, 'rougeLsum': 0.3484233231283168}*\n",
    "\n",
    "**SK** *{'rouge1': 0.5935977294706721, 'rouge2': 0.4272281779017747, 'rougeL': 0.5711202748270763, 'rougeLsum': 0.5709580363216058}*\n",
    "\n",
    "`qg/google/mt5-large_all/BKP/checkpoint-126000`\n",
    "\n",
    "**ALL** *{'rouge1': 0.4712879903083035, 'rouge2': 0.2790771005345815,  'rougeL': 0.44412574432094815,  'rougeLsum': 0.4440181809982411}*\n",
    "\n",
    "**CS** **{'rouge1': 0.37076781953491367, 'rouge2': 0.19188317187558196, 'rougeL': 0.34603606602711284, 'rougeLsum': 0.3458732199471718}**\n",
    "\n",
    "**EN** *{'rouge1': 0.4972121341475896, 'rouge2': 0.27814731357909395, 'rougeL': 0.46391560371478174, 'rougeLsum': 0.46394229428970657}*\n",
    "\n",
    "**PL** **{'rouge1': 0.3717109027777702, 'rouge2': 0.20806629045849118, 'rougeL': 0.35534417379213407, 'rougeLsum': 0.35545025872361985}**\n",
    "\n",
    "**SK** **{'rouge1': 0.6120836094748034, 'rouge2': 0.4468872126953193, 'rougeL': 0.5898635208080331, 'rougeLsum': 0.5898424756234816}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for model inference\n",
    "see `scripts/wiki_qg.py` for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CZ\n",
    "lang = \"cs_CZ\"\n",
    "# model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/facebook/mbart-large-cc25_cs_CZ/BEST/checkpoint-32000\")\n",
    "\n",
    "# SK\n",
    "lang = \"sk_SK\"\n",
    "model_args = ModelArguments(model_name_or_path=\"/home/drchajan/devel/python/FC/Zero-shot-Fact-Verification/experiments/qg/google/mt5-large_sk_SK/checkpoint-37000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, data_collator = load_tokenizer_and_model(model_args, lang=lang, fp16=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS\n",
    "# data = read_jsonl(\"/mnt/data/factcheck/qg/squad-cs/dev-v1.1.json\")\n",
    "\n",
    "# SK\n",
    "data = read_jsonl(\"/mnt/data/factcheck/qg/sk-quad-220614/sk-quad-220614-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Vysoký grúň (Laborecká vrchovina)',\n",
       " 'context': 'Cez vrch Vysoký grúň vedie hlavná  červená turistická značka, ktorá zároveň vedie po hlavnom karpatskom hrebeni cez najvýchodnejší bod Slovenska – trojmedzie (1207.7 Mnm) na vrchu Kremenec (1221.0 Mnm) a prechádza po slovensko-poľskej štátnej hranici cez viacero vrchov s viacerými panoramatickými vyhliadkami, ako napr. Kamenná lúka (1200.9 Mnm), Jarabá skala (1199.0 Mnm), Ďurkovec (1188.7 Mnm), Pľaša (1162.8 Mnm), ďalej cez Ruské sedlo (801.0 Mnm), vrchy Rypy (1002.7 Mnm), Strop, (1011.2 Mnm), Černiny (929.4 Mnm), Laborecký priesmyk (684.0 Mnm) až k Duklianskemu priesmyku (502.0 Mnm).',\n",
       " 'question': 'Akú nadmorskú výšku má vrch Kremenec?',\n",
       " 'answer': '1221.0 Mnm'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy\n",
      "Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura\n",
      "Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky\n",
      "v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo\n",
      "působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform\n",
      "mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově\n",
      "Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby\n",
      "Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s\n",
      "vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o\n",
      "pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s\n",
      "ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli\n",
      "kvůli vzdušnému poplachu v pátek na čas do hotelového krytu.\n",
      "Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a\n",
      "Slovenska poznamenala, že vysoce postavení zahraniční představitelé od\n",
      "začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\n",
      "NATO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['V ktorom štáte pôsobil prezident Pavlo Pavlov na vrcholnej pozicii?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, tokenizer, inputs, max_source_length=1024, padding=False):\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        Y = model.generate(**model_inputs, max_new_tokens=768)\n",
    "        predictions = tokenizer.batch_decode(\n",
    "            Y, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return predictions\n",
    "\n",
    "\n",
    "sample = data[120]\n",
    "answer = sample[\"answer\"]\n",
    "context = \"Vzkaz na vojenské technice zaujal po sobotní části Pavlovy návštěvy Ukrajiny některá ukrajinská média. Píše o něm také kupříkladu agentura Unian, která zároveň informuje o Pavlově setkání s ukrajinskými vojáky v Dněpropetrovské oblasti, agentura Ukrinform, jež připomněla Pavlovo působení na vrcholné pozici v NATO, nebo server Obozrevatel. Ukrinform mimo jiné zaznamenal jednání prezidenta s místními činiteli o obnově Dněpropetrovské oblasti, nad níž Česko převzalo záštitu. Weby Hromadske nebo Jevropejska pravda upozornily na prezidentovo setkání s vysídlenými Ukrajinci. Ukrajinská média informovala už dříve o pátečním programu Pavla a Čaputové, kromě jejich oficiálních setkání s ukrajinskými činiteli si povšimla mimo jiné faktu, že státníci museli kvůli vzdušnému poplachu v pátek na čas do hotelového krytu. Ukrajinska pravda v souvislosti s návštěvou prezidentů Česka a Slovenska poznamenala, že vysoce postavení zahraniční představitelé od začátku ruské invaze jen zřídka zůstali na Ukrajině přes noc.\"\n",
    "answer = \"NATO\"\n",
    "print(textwrap.fill(context))\n",
    "print(answer)\n",
    "predict(model, tokenizer, [answer + \"</s>\" + context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32150, 1024)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "model_id = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "accents = \"áčďéěíňóřšťúůýž\" # CS\n",
    "accents += \"ąćęłńóśźż\" # PL\n",
    "accents += \"áäčďéíĺľňóôŕšťúýž\" # SK\n",
    "accents += accents.upper()\n",
    "accents = set(c for c in accents)\n",
    "new_tokens = accents - set(tokenizer.vocab.keys())\n",
    "\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53385a98a1e4eca9a5d2b8095d29e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008115768432617188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 3001279361,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806913f99a494f26bff1d0cd07d95828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016201257705688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b8ff0c1954808beb0a414dd7cda53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/44e85df0c017c2ee04a322a13ddd14d0674f357d', commit_message='Upload model', commit_description='', oid='44e85df0c017c2ee04a322a13ddd14d0674f357d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008070945739746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload 1 LFS files",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4969ea29d072489eb0b6448a8201b0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00809168815612793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "spiece.model",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dbb221150a46b1be926a0aef862f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ctu-aic/flan-t5-large/commit/6e995ffb333de1a0238236976bc7a9271ddf1e3a', commit_message='Upload tokenizer', commit_description='', oid='6e995ffb333de1a0238236976bc7a9271ddf1e3a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"ctu-aic/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nechť již hříš né saxofony ď áblů rozezvučí síň ú dě sný mi tóny waltzu, tanga a quickstepu.</s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Nechť již hříšné saxofony ďáblů rozezvučí síň úděsnými tóny waltzu, tanga a quickstepu.\"\n",
    "ids = tokenizer(txt)[\"input_ids\"]\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1484,\n",
       " 524,\n",
       " 2,\n",
       " 3,\n",
       " 354,\n",
       " 23,\n",
       " 2,\n",
       " 3,\n",
       " 107,\n",
       " 2,\n",
       " 29,\n",
       " 154,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 226,\n",
       " 858,\n",
       " 106,\n",
       " 63,\n",
       " 3,\n",
       " 2,\n",
       " 2975,\n",
       " 115,\n",
       " 40,\n",
       " 2,\n",
       " 3,\n",
       " 9860,\n",
       " 457,\n",
       " 208,\n",
       " 76,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 2,\n",
       " 7,\n",
       " 29,\n",
       " 2,\n",
       " 51,\n",
       " 23,\n",
       " 3,\n",
       " 17,\n",
       " 15742,\n",
       " 63,\n",
       " 3,\n",
       " 5380,\n",
       " 17,\n",
       " 1000,\n",
       " 6,\n",
       " 3,\n",
       " 8967,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 1704,\n",
       " 7910,\n",
       " 76,\n",
       " 5,\n",
       " 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Á',\n",
       " 'Ä',\n",
       " 'Í',\n",
       " 'Ó',\n",
       " 'Ô',\n",
       " 'Ú',\n",
       " 'Ý',\n",
       " 'í',\n",
       " 'ú',\n",
       " 'ý',\n",
       " 'Ą',\n",
       " 'ą',\n",
       " 'Ć',\n",
       " 'ć',\n",
       " 'Č',\n",
       " 'č',\n",
       " 'Ď',\n",
       " 'ď',\n",
       " 'Ę',\n",
       " 'ę',\n",
       " 'Ě',\n",
       " 'ě',\n",
       " 'Ĺ',\n",
       " 'ĺ',\n",
       " 'Ľ',\n",
       " 'ľ',\n",
       " 'Ł',\n",
       " 'ł',\n",
       " 'Ń',\n",
       " 'ń',\n",
       " 'Ň',\n",
       " 'ň',\n",
       " 'Ŕ',\n",
       " 'ŕ',\n",
       " 'Ř',\n",
       " 'ř',\n",
       " 'Ś',\n",
       " 'ś',\n",
       " 'Š',\n",
       " 'š',\n",
       " 'Ť',\n",
       " 'ť',\n",
       " 'Ů',\n",
       " 'ů',\n",
       " 'Ź',\n",
       " 'ź',\n",
       " 'Ż',\n",
       " 'ż',\n",
       " 'Ž',\n",
       " 'ž'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32100, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hflarge",
   "language": "python",
   "name": "hflarge"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
